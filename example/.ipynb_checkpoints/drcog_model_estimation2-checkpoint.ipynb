{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Paris Model Estimation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variable Library"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd, os, statsmodels.api as sm\n",
      "import synthicity.urbansim.interaction as interaction\n",
      "from synthicity.utils import misc\n",
      "import dataset, copy, time\n",
      "dset = dataset.DRCOGDataset(os.path.join(misc.data_dir(),'drcog.h5'))\n",
      "#VARIABLE LIBRARY\n",
      "#parcel\n",
      "p = dset.fetch('parcels')\n",
      "p['in_denver'] = (p.county_id==8031).astype('int32')\n",
      "#building\n",
      "b = dset.fetch('buildings')\n",
      "b['zone_id'] = p.zone_id[b.parcel_id].values\n",
      "b['btype'] = 1*(b.building_type_id==2) + 2*(b.building_type_id==3) + 3*(b.building_type_id==20) + 4*(b.building_type_id==24) + 6*np.invert(np.in1d(b.building_type_id,[2,3,20,24]))\n",
      "#household\n",
      "hh_estim = dset.fetch('households_for_estimation')\n",
      "hh = dset.fetch('households')\n",
      "for table in [hh_estim, hh]:\n",
      "    choosers = table\n",
      "    choosers['building_type_id'] = b.building_type_id[choosers.building_id].values\n",
      "    choosers['btype'] = 1*(choosers.building_type_id==2) + 2*(choosers.building_type_id==3) + 3*(choosers.building_type_id==20) + 4*np.invert(np.in1d(choosers.building_type_id,[2,3,20]))\n",
      "#establishment\n",
      "e = dset.fetch('establishments')\n",
      "e['sector_id_six'] = 1*(e.sector_id==61) + 2*(e.sector_id==71) + 3*np.in1d(e.sector_id,[11,21,22,23,31,32,33,42,48,49]) + 4*np.in1d(e.sector_id,[7221,7222,7224]) + 5*np.in1d(e.sector_id,[44,45,7211,7212,7213,7223]) + 6*np.in1d(e.sector_id,[51,52,53,54,55,56,62,81,92])\n",
      "#zone\n",
      "z = dset.fetch('zones')\n",
      "z['residential_units_zone'] = b.groupby('zone_id').residential_units.sum()\n",
      "z['non_residential_sqft_zone'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "#merge parcels with zones\n",
      "pz = pd.merge(p,z,left_on='zone_id',right_index=True)\n",
      "#merge buildings with parcels/zones\n",
      "bpz = pd.merge(b,pz,left_on='parcel_id',right_index=True)\n",
      "bpz['residential_units_capacity'] = bpz.parcel_sqft/1500 - bpz.residential_units\n",
      "bpz.residential_units_capacity[bpz.residential_units_capacity<0] = 0\n",
      "dset.d['buildings'] = bpz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching parcels\n",
        "Fetching modify_table\n",
        "Fetching buildings"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching establishments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching households_for_estimation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table\n",
        "Fetching households\n",
        "Fetching modify_table\n",
        "Fetching zones"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Household Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'building_id'\n",
      "SAMPLE_SIZE=100\n",
      "choosers = dset.fetch('households_for_estimation')\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 10000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-hlcm-%s.csv\",\"DRCOG HOUSEHOLD LOCATION CHOICE MODELS (%s)\",\"hh_location_%s\",\"household_building_ids\")\n",
      "\n",
      "#alternatives = dset.buildings[(dset.buildings.residential_units>0)]\n",
      "alternatives = dset.buildings\n",
      "# alts1 = alternatives[alternatives.building_type_id==2]\n",
      "# alts2 = alternatives[alternatives.building_type_id==3]\n",
      "# alts3 = alternatives[alternatives.building_type_id==20]\n",
      "# alts4 = alternatives[alternatives.building_type_id==24]\n",
      "alts1 = alternatives\n",
      "alts2 = alternatives\n",
      "alts3 = alternatives\n",
      "alts4 = alternatives\n",
      "\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','unit_price_residential','in_denver',] \n",
      "\n",
      "segments = choosers.groupby(['btype',])\n",
      "for name, segment in segments:\n",
      "    if name == 1:\n",
      "        alts = alts1\n",
      "        ind_vars = ind_vars1\n",
      "    if name == 2:\n",
      "        alts = alts2\n",
      "        ind_vars = ind_vars2\n",
      "    if name == 3:\n",
      "        alts = alts3\n",
      "        ind_vars = ind_vars3\n",
      "    if name == 4:\n",
      "        alts = alts4\n",
      "        ind_vars = ind_vars4\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.building_id) > 500: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 500,replace=False)]\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    #alternative_sample['high_inc_x_percent_high_inc'] = (alternative_sample.high_inc*alternative_sample.percent_high_income)\n",
      "    #alternative_sample['interaction_test2'] = (alternative_sample.low_inc*alternative_sample.mean_age_of_head)\n",
      "#     if int(name)==1:\n",
      "#         alternative_sample['ln_price1_x_low_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.low_inc)\n",
      "#     if int(name)==2:\n",
      "#         alternative_sample['ln_price2_x_low_income'] = (alternative_sample.ln_average_res_price2*alternative_sample.low_inc)\n",
      "#     if int(name)==3:\n",
      "#         alternative_sample['ln_price3_x_low_income'] = (alternative_sample.ln_average_res_price3*alternative_sample.low_inc)\n",
      "#     if int(name)==4:\n",
      "#         alternative_sample['ln_price4_x_low_income'] = (alternative_sample.ln_average_res_price4*alternative_sample.low_inc)\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "        try:\n",
      "            fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "            #print fit\n",
      "            #print results\n",
      "            fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "            print misc.resultstotable(fnames,results)\n",
      "            misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "            dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "        except:\n",
      "            print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimating parameters for segment = 1, size = 231\n",
        "Null Log-liklihood: -1063.794313"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -784.619966\n",
        "Log-liklihood ratio: 0.262433\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |  12.930 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   3.100 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.130 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |      -0.010 |      0 | -42.730 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 | -29.620 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.150 |   0.010 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 2, size = 162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -746.037570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -569.521345\n",
        "Log-liklihood ratio: 0.236605\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |  14.630 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   0.620 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.020 |   0.160 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |      -0.010 |      0 | -13.360 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |   1.630 | .            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.210 |   0.010 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 3, size = 500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -2302.585093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -2283.244158\n",
        "Log-liklihood ratio: 0.008400\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   1.810 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  -1.930 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |  -0.770 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |   6.540 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.110 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 4, size = 162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -746.037570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -735.863572\n",
        "Log-liklihood ratio: 0.013637\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   0.830 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   3.100 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |  -3.020 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.170 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Establishment Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'building_id'\n",
      "SAMPLE_SIZE=50\n",
      "choosers = dset.fetch('establishments')\n",
      "choosers = choosers[(choosers.building_id>0)*(choosers.home_based_status==0)]\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 150000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-elcm-%s.csv\",\"DRCOG EMPLOYMENT LOCATION CHOICE MODELS (%s)\",\"emp_location_%s\",\"establishment_building_ids\")\n",
      "\n",
      "#alts = dset.buildings[(dset.buildings.non_residential_sqft>0)]\n",
      "alts = dset.buildings\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "segments = choosers.groupby(['sector_id_six',])\n",
      "for name, segment in segments:\n",
      "    print name\n",
      "    if name == 1:\n",
      "        ind_vars = ind_vars1 #interaction w/ employees\n",
      "    if name == 2:\n",
      "        ind_vars = ind_vars2 #big estabs are price sensitive\n",
      "    if name == 3:\n",
      "        ind_vars = ind_vars3 #negative price alone! yay!\n",
      "    if name == 4:\n",
      "        ind_vars = ind_vars4 #big estabs are price sensitive\n",
      "    if name == 5:\n",
      "        ind_vars = ind_vars5 #big estabs are price sensitive\n",
      "    if name == 6:\n",
      "        ind_vars = ind_vars6 #small estabs are price sensitive\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.building_id) > 6000: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 6000,replace=False)]\n",
      "    #sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar],weight_var='non_residential_sqft')\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    #alternative_sample['paris_x_employees'] = (alternative_sample.in_paris*alternative_sample.employees)\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "        try:\n",
      "            fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "            #print fit\n",
      "            #print results\n",
      "            fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "            print misc.resultstotable(fnames,results)\n",
      "            misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "            dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "        except:\n",
      "            print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "Estimating parameters for segment = 1, size = 3051"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -11935.582190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -11392.195684\n",
        "Log-liklihood ratio: 0.045527\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -19.610 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  30.540 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.050 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -12.700 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |  -0.020 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.050 |       0 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "2\n",
        "Estimating parameters for segment = 2, size = 1752"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -6853.864306"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -6472.315837\n",
        "Log-liklihood ratio: 0.055669\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -24.940 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  19.980 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.050 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 |  -2.550 | **           |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   1.190 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.060 |       0 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "3\n",
        "Estimating parameters for segment = 3, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -20775.831573\n",
        "Log-liklihood ratio: 0.114873\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -56.910 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  66.730 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.160 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -12.600 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.210 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "4\n",
        "Estimating parameters for segment = 4, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21504.399204\n",
        "Log-liklihood ratio: 0.083833\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -41.170 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  56.490 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |   0.180 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -44.190 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.020 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "5\n",
        "Estimating parameters for segment = 5, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21291.008770\n",
        "Log-liklihood ratio: 0.092924\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -45.610 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  64.680 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.160 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -30.330 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.020 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "6\n",
        "Estimating parameters for segment = 6, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21577.735450\n",
        "Log-liklihood ratio: 0.080709\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -35.860 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  61.310 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.090 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -36.450 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.620 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Development Project Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'parcel_id'\n",
      "SAMPLE_SIZE=100\n",
      "choosers = dset.fetch('buildings')\n",
      "#p_nsqft = choosers.groupby('parcel_id').non_residential_sqft.sum()\n",
      "choosers = choosers[choosers.year_built>2000]\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 150000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-dplcm-%s.csv\",\"DRCOG DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "\n",
      "alts = pd.merge(dset.parcels,dset.zones,left_on='zone_id',right_index=True)\n",
      "alts['capacity'] = alts.parcel_sqft\n",
      "# alts1 = alts[alts.building_type_id==1]\n",
      "# alts2 = alts[alts.building_type_id==2]\n",
      "# alts3 = alts[alts.building_type_id==3]\n",
      "# alts4 = alts[alts.building_type_id==4]\n",
      "# alts6 = alts[alts.building_type_id==6]\n",
      "alts1 = alts\n",
      "alts2 = alts\n",
      "alts3 = alts\n",
      "alts4 = alts\n",
      "alts6 = alts\n",
      "\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "\n",
      "segments = choosers.groupby(['btype',])\n",
      "for name, segment in segments:\n",
      "    if name == 1:\n",
      "        alts = alts1\n",
      "        ind_vars = ind_vars1\n",
      "    if name == 2:\n",
      "        alts = alts2\n",
      "        ind_vars = ind_vars2\n",
      "    if name == 3:\n",
      "        alts = alts3\n",
      "        ind_vars = ind_vars3\n",
      "    if name == 4:\n",
      "        alts = alts4\n",
      "        ind_vars = ind_vars4\n",
      "    if name == 6:\n",
      "        alts = alts6\n",
      "        ind_vars = ind_vars6\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.parcel_id) > 1000: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 1000,replace=False)]\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "#         try:\n",
      "        fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "        #print fit\n",
      "        #print results\n",
      "        fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "        print misc.resultstotable(fnames,results)\n",
      "        misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "        dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "#         except:\n",
      "#             print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimating parameters for segment = 1, size = 1000\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4446.502275\n",
        "Log-liklihood ratio: 0.034454\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   8.310 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   8.390 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |       0.120 |  0.010 |  18.170 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 | -11.850 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |      -0.360 |  0.080 |  -4.320 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 2, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4521.250869\n",
        "Log-liklihood ratio: 0.018223\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   5.120 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |       5 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.020 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 | -19.680 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.110 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 3, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4505.757837\n",
        "Log-liklihood ratio: 0.021587\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   2.330 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  -6.450 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |      -0.160 |  0.010 | -25.890 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |  -4.850 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |      -0.050 |  0.120 |  -0.390 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 4, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4501.630361\n",
        "Log-liklihood ratio: 0.022483\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   7.530 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   1.680 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.030 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |  -7.900 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.070 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 6, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4219.034220\n",
        "Log-liklihood ratio: 0.083848\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 | -20.550 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  25.730 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |      0 |  -0.090 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |   1.960 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.110 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dset.coeffs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Int64Index: 6 entries, 0 to 5\n",
        "Data columns (total 30 columns):\n",
        "(hh_location_1, coeffs)     6  non-null values\n",
        "(hh_location_1, fnames)     6  non-null values\n",
        "(hh_location_2, coeffs)     6  non-null values\n",
        "(hh_location_2, fnames)     6  non-null values\n",
        "(hh_location_3, coeffs)     6  non-null values\n",
        "(hh_location_3, fnames)     6  non-null values\n",
        "(hh_location_4, coeffs)     4  non-null values\n",
        "(hh_location_4, fnames)     4  non-null values\n",
        "(emp_location_1, coeffs)    6  non-null values\n",
        "(emp_location_1, fnames)    6  non-null values\n",
        "(emp_location_2, coeffs)    6  non-null values\n",
        "(emp_location_2, fnames)    6  non-null values\n",
        "(emp_location_3, coeffs)    6  non-null values\n",
        "(emp_location_3, fnames)    6  non-null values\n",
        "(emp_location_4, coeffs)    6  non-null values\n",
        "(emp_location_4, fnames)    6  non-null values\n",
        "(emp_location_5, coeffs)    6  non-null values\n",
        "(emp_location_5, fnames)    6  non-null values\n",
        "(emp_location_6, coeffs)    6  non-null values\n",
        "(emp_location_6, fnames)    6  non-null values\n",
        "(dp_location_1, coeffs)     5  non-null values\n",
        "(dp_location_1, fnames)     5  non-null values\n",
        "(dp_location_2, coeffs)     5  non-null values\n",
        "(dp_location_2, fnames)     5  non-null values\n",
        "(dp_location_3, coeffs)     5  non-null values\n",
        "(dp_location_3, fnames)     5  non-null values\n",
        "(dp_location_4, coeffs)     5  non-null values\n",
        "(dp_location_4, fnames)     5  non-null values\n",
        "(dp_location_6, coeffs)     5  non-null values\n",
        "(dp_location_6, fnames)     5  non-null values\n",
        "dtypes: float64(15), object(15)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 6 entries, 0 to 5\n",
        "Data columns (total 30 columns):\n",
        "(hh_location_1, coeffs)     6  non-null values\n",
        "(hh_location_1, fnames)     6  non-null values\n",
        "(hh_location_2, coeffs)     6  non-null values\n",
        "(hh_location_2, fnames)     6  non-null values\n",
        "(hh_location_3, coeffs)     6  non-null values\n",
        "(hh_location_3, fnames)     6  non-null values\n",
        "(hh_location_4, coeffs)     4  non-null values\n",
        "(hh_location_4, fnames)     4  non-null values\n",
        "(emp_location_1, coeffs)    6  non-null values\n",
        "(emp_location_1, fnames)    6  non-null values\n",
        "(emp_location_2, coeffs)    6  non-null values\n",
        "(emp_location_2, fnames)    6  non-null values\n",
        "(emp_location_3, coeffs)    6  non-null values\n",
        "(emp_location_3, fnames)    6  non-null values\n",
        "(emp_location_4, coeffs)    6  non-null values\n",
        "(emp_location_4, fnames)    6  non-null values\n",
        "(emp_location_5, coeffs)    6  non-null values\n",
        "(emp_location_5, fnames)    6  non-null values\n",
        "(emp_location_6, coeffs)    6  non-null values\n",
        "(emp_location_6, fnames)    6  non-null values\n",
        "(dp_location_1, coeffs)     5  non-null values\n",
        "(dp_location_1, fnames)     5  non-null values\n",
        "(dp_location_2, coeffs)     5  non-null values\n",
        "(dp_location_2, fnames)     5  non-null values\n",
        "(dp_location_3, coeffs)     5  non-null values\n",
        "(dp_location_3, fnames)     5  non-null values\n",
        "(dp_location_4, coeffs)     5  non-null values\n",
        "(dp_location_4, fnames)     5  non-null values\n",
        "(dp_location_6, coeffs)     5  non-null values\n",
        "(dp_location_6, fnames)     5  non-null values\n",
        "dtypes: float64(15), object(15)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Real Estate Price Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# buildings = dset.fetch('buildings')\n",
      "# buildings = buildings[buildings.estim_index==1]\n",
      "# output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic.csv\",\"PARIS HEDONIC MODEL\",\"price_%s\",\"price\"]\n",
      "\n",
      "# ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "#              'employment_density','tax_on_professionals','tco',]\n",
      "\n",
      "# segments = buildings.groupby('building_type_id')\n",
      "# for name, segment in segments:\n",
      "#     if name == 1:\n",
      "#         indvars = ind_vars1\n",
      "#     if name == 2:\n",
      "#         indvars = ind_vars2\n",
      "#     if name == 3:\n",
      "#         indvars = ind_vars3\n",
      "#     if name == 4:\n",
      "#         indvars = ind_vars4\n",
      "#     if name == 6:\n",
      "#         indvars = ind_vars6\n",
      "#     est_data = pd.DataFrame(index=segment.index)\n",
      "#     for varname in indvars:\n",
      "#         est_data[varname] = segment[varname]\n",
      "#     est_data = est_data.fillna(0)\n",
      "#     est_data = sm.add_constant(est_data,prepend=False)\n",
      "#     tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "#     print segment\n",
      "#     depvar = segment['price'].apply(np.log)\n",
      "#     print \"Estimating hedonic for %s with %d observations\" % (name,len(segment.index))\n",
      "#     print est_data.describe()\n",
      "\n",
      "#     model = sm.OLS(depvar,est_data)\n",
      "#     results = model.fit()\n",
      "#     print results.summary()\n",
      "\n",
      "#     tmp_outcsv = output_csv%name\n",
      "#     tmp_outtitle = output_title%name\n",
      "#     misc.resultstocsv((results.rsquared,results.rsquared_adj),est_data.columns,\n",
      "#                         zip(results.params,results.bse,results.tvalues),tmp_outcsv,hedonic=1,\n",
      "#                         tblname=output_title)\n",
      "\n",
      "#     dset.store_coeff(tmp_coeffname,results.params.values,results.params.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Coefficients to HDF5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##COEFFICIENTS TO HDF5\n",
      "# coeff_store_path = os.path.join(output_dir,'coeffs.h5')\n",
      "# coeff_store = pd.HDFStore(coeff_store_path)\n",
      "# coeff_store['coeffs'] = dset.coeffs\n",
      "# coeff_store.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dset.buildings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Int64Index: 881750 entries, 55152 to 1015771\n",
        "Data columns (total 76 columns):\n",
        "building_type_id              881750  non-null values\n",
        "improvement_value             881750  non-null values\n",
        "land_area                     881750  non-null values\n",
        "non_residential_sqft          881750  non-null values\n",
        "parcel_id                     881750  non-null values\n",
        "residential_units             881750  non-null values\n",
        "sqft_per_unit                 881750  non-null values\n",
        "stories                       881750  non-null values\n",
        "tax_exempt                    881750  non-null values\n",
        "year_built                    881750  non-null values\n",
        "bldg_sq_ft                    881750  non-null values\n",
        "unit_price_non_residential    881750  non-null values\n",
        "unit_price_residential        881750  non-null values\n",
        "zone_id_x                     881750  non-null values\n",
        "building_sqft_per_job         881750  non-null values\n",
        "non_residential_units         881750  non-null values\n",
        "base_year_jobs                104226  non-null values\n",
        "all_units                     881750  non-null values\n",
        "btype                         881750  non-null values\n",
        "county_id                     881750  non-null values\n",
        "parcel_sqft                   881750  non-null values\n",
        "land_value                    881750  non-null values\n",
        "zone_id_y                     881750  non-null values\n",
        "city_id                       881750  non-null values\n",
        "gen_lu_type_id                881750  non-null values\n",
        "lu_type_id                    881750  non-null values\n",
        "tax_exempt_flag               881750  non-null values\n",
        "school_district               881750  non-null values\n",
        "zoning_id                     881750  non-null values\n",
        "dist_bus                      881750  non-null values\n",
        "dist_rail                     881750  non-null values\n",
        "in_ugb                        881750  non-null values\n",
        "in_uga                        881750  non-null values\n",
        "env_constr_park               881750  non-null values\n",
        "env_constr_lake               881750  non-null values\n",
        "env_constr_floodplain         881750  non-null values\n",
        "env_constr_river              881750  non-null values\n",
        "env_constr_landslide          881750  non-null values\n",
        "far_id                        881750  non-null values\n",
        "prop_constrained              881750  non-null values\n",
        "in_denver                     881750  non-null values\n",
        "external_zone_id              881750  non-null values\n",
        "area                          881750  non-null values\n",
        "acreage                       881750  non-null values\n",
        "modelarea                     881750  non-null values\n",
        "area_type                     881750  non-null values\n",
        "zonecentroid_x                881750  non-null values\n",
        "zonecentroid_y                881750  non-null values\n",
        "county                        881750  non-null values\n",
        "numtransstops                 881750  non-null values\n",
        "averagedailyparkingcost       881750  non-null values\n",
        "intrdenshhbuffer              881750  non-null values\n",
        "intrdensempbuffer             881750  non-null values\n",
        "private_pk8enrollment         881750  non-null values\n",
        "public_pk8enrollment          881750  non-null values\n",
        "total_pk8enrollment           881750  non-null values\n",
        "private_912enrollment         881750  non-null values\n",
        "public_912enrollment          881750  non-null values\n",
        "total_912enrollment           881750  non-null values\n",
        "universityenrollment          881750  non-null values\n",
        "schooldistrictzone            881750  non-null values\n",
        "schooldistrictname            881750  non-null values\n",
        "newdistrictname               881750  non-null values\n",
        "newdistrictid                 881750  non-null values\n",
        "totalzonalenrollment          881750  non-null values\n",
        "escort_agglogsum              881750  non-null values\n",
        "persbus_agglogsum             881750  non-null values\n",
        "shop_agglogsum                881750  non-null values\n",
        "meal_agglogsum                881750  non-null values\n",
        "socrec_agglogsum              881750  non-null values\n",
        "workbasedsubtour_agglogsum    881750  non-null values\n",
        "allpurpose_agglosum           881750  non-null values\n",
        "school_district_id            881750  non-null values\n",
        "residential_units_zone        881750  non-null values\n",
        "non_residential_sqft_zone     881750  non-null values\n",
        "residential_units_capacity    881750  non-null values\n",
        "dtypes: float32(23), float64(7), int32(43), object(3)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 881750 entries, 55152 to 1015771\n",
        "Data columns (total 76 columns):\n",
        "building_type_id              881750  non-null values\n",
        "improvement_value             881750  non-null values\n",
        "land_area                     881750  non-null values\n",
        "non_residential_sqft          881750  non-null values\n",
        "parcel_id                     881750  non-null values\n",
        "residential_units             881750  non-null values\n",
        "sqft_per_unit                 881750  non-null values\n",
        "stories                       881750  non-null values\n",
        "tax_exempt                    881750  non-null values\n",
        "year_built                    881750  non-null values\n",
        "bldg_sq_ft                    881750  non-null values\n",
        "unit_price_non_residential    881750  non-null values\n",
        "unit_price_residential        881750  non-null values\n",
        "zone_id_x                     881750  non-null values\n",
        "building_sqft_per_job         881750  non-null values\n",
        "non_residential_units         881750  non-null values\n",
        "base_year_jobs                104226  non-null values\n",
        "all_units                     881750  non-null values\n",
        "btype                         881750  non-null values\n",
        "county_id                     881750  non-null values\n",
        "parcel_sqft                   881750  non-null values\n",
        "land_value                    881750  non-null values\n",
        "zone_id_y                     881750  non-null values\n",
        "city_id                       881750  non-null values\n",
        "gen_lu_type_id                881750  non-null values\n",
        "lu_type_id                    881750  non-null values\n",
        "tax_exempt_flag               881750  non-null values\n",
        "school_district               881750  non-null values\n",
        "zoning_id                     881750  non-null values\n",
        "dist_bus                      881750  non-null values\n",
        "dist_rail                     881750  non-null values\n",
        "in_ugb                        881750  non-null values\n",
        "in_uga                        881750  non-null values\n",
        "env_constr_park               881750  non-null values\n",
        "env_constr_lake               881750  non-null values\n",
        "env_constr_floodplain         881750  non-null values\n",
        "env_constr_river              881750  non-null values\n",
        "env_constr_landslide          881750  non-null values\n",
        "far_id                        881750  non-null values\n",
        "prop_constrained              881750  non-null values\n",
        "in_denver                     881750  non-null values\n",
        "external_zone_id              881750  non-null values\n",
        "area                          881750  non-null values\n",
        "acreage                       881750  non-null values\n",
        "modelarea                     881750  non-null values\n",
        "area_type                     881750  non-null values\n",
        "zonecentroid_x                881750  non-null values\n",
        "zonecentroid_y                881750  non-null values\n",
        "county                        881750  non-null values\n",
        "numtransstops                 881750  non-null values\n",
        "averagedailyparkingcost       881750  non-null values\n",
        "intrdenshhbuffer              881750  non-null values\n",
        "intrdensempbuffer             881750  non-null values\n",
        "private_pk8enrollment         881750  non-null values\n",
        "public_pk8enrollment          881750  non-null values\n",
        "total_pk8enrollment           881750  non-null values\n",
        "private_912enrollment         881750  non-null values\n",
        "public_912enrollment          881750  non-null values\n",
        "total_912enrollment           881750  non-null values\n",
        "universityenrollment          881750  non-null values\n",
        "schooldistrictzone            881750  non-null values\n",
        "schooldistrictname            881750  non-null values\n",
        "newdistrictname               881750  non-null values\n",
        "newdistrictid                 881750  non-null values\n",
        "totalzonalenrollment          881750  non-null values\n",
        "escort_agglogsum              881750  non-null values\n",
        "persbus_agglogsum             881750  non-null values\n",
        "shop_agglogsum                881750  non-null values\n",
        "meal_agglogsum                881750  non-null values\n",
        "socrec_agglogsum              881750  non-null values\n",
        "workbasedsubtour_agglogsum    881750  non-null values\n",
        "allpurpose_agglosum           881750  non-null values\n",
        "school_district_id            881750  non-null values\n",
        "residential_units_zone        881750  non-null values\n",
        "non_residential_sqft_zone     881750  non-null values\n",
        "residential_units_capacity    881750  non-null values\n",
        "dtypes: float32(23), float64(7), int32(43), object(3)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = '_ref_base'\n",
      "for scenario in ['baseline',]: #'low_impact','scen0'\n",
      "    print 'Running scenario: ' + scenario\n",
      "    import time\n",
      "    seconds_start = time.time()\n",
      "    print seconds_start\n",
      "    import numpy as np, pandas as pd, os, statsmodels.api as sm\n",
      "    import synthicity.urbansim.interaction as interaction\n",
      "    from synthicity.utils import misc\n",
      "    import dataset, copy, math\n",
      "    np.random.seed(1)\n",
      "    first_year = 2010\n",
      "    last_year = 2020\n",
      "    summary = {'employment':[],'households':[],'non_residential_sqft':[],'residential_units':[],'price':[]}\n",
      "#     dset = dataset.DRCOGDataset(os.path.join(misc.data_dir(),'drcog.h5'))\n",
      "    \n",
      "    for sim_year in range(first_year,last_year+1):\n",
      "        print 'Simulating year ' + str(sim_year)\n",
      "        \n",
      "    #####Variable calculations\n",
      "#         p = dset.fetch('parcels')\n",
      "#         p['in_denver'] = (p.county_id==8031).astype('int32')\n",
      "#         #building\n",
      "#         b = dset.fetch('buildings')\n",
      "#         b['zone_id'] = p.zone_id[b.parcel_id].values\n",
      "#         b['btype'] = 1*(b.building_type_id==2) + 2*(b.building_type_id==3) + 3*(b.building_type_id==20) + 4*(b.building_type_id==24) + 6*np.invert(np.in1d(b.building_type_id,[2,3,20,24]))\n",
      "#         #household\n",
      "#         hh_estim = dset.fetch('households_for_estimation')\n",
      "#         hh = dset.fetch('households')\n",
      "#         for table in [hh_estim, hh]:\n",
      "#             choosers = table\n",
      "#             choosers['building_type_id'] = b.building_type_id[choosers.building_id].values\n",
      "#             choosers['btype'] = 1*(choosers.building_type_id==2) + 2*(choosers.building_type_id==3) + 3*(choosers.building_type_id==20) + 4*np.invert(np.in1d(choosers.building_type_id,[2,3,20]))\n",
      "#         #establishment\n",
      "#         e = dset.fetch('establishments')\n",
      "#         e['sector_id_six'] = 1*(e.sector_id==61) + 2*(e.sector_id==71) + 3*np.in1d(e.sector_id,[11,21,22,23,31,32,33,42,48,49]) + 4*np.in1d(e.sector_id,[7221,7222,7224]) + 5*np.in1d(e.sector_id,[44,45,7211,7212,7213,7223]) + 6*np.in1d(e.sector_id,[51,52,53,54,55,56,62,81,92])\n",
      "#         #zone\n",
      "#         z = dset.fetch('zones')\n",
      "#         z['residential_units_zone'] = b.groupby('zone_id').residential_units.sum()\n",
      "#         z['non_residential_sqft_zone'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "#         #merge parcels with zones\n",
      "#         pz = pd.merge(p,z,left_on='zone_id',right_index=True)\n",
      "#         #merge buildings with parcels/zones\n",
      "#         dset.d['buildings'] = pd.merge(b,pz,left_on='parcel_id',right_index=True)\n",
      "        \n",
      "        #Record base values for temporal comparison\n",
      "        if sim_year==first_year:\n",
      "            summary['employment'].append(e[e.building_id>0].employees.sum())\n",
      "            summary['households'].append(len(hh[hh.building_id>0].building_id))\n",
      "            summary['non_residential_sqft'].append(b.non_residential_sqft.sum())\n",
      "            summary['residential_units'].append(b.residential_units.sum())\n",
      "\n",
      "#             base_emp = z.groupby('zgpgroup_id').total_employment.sum()\n",
      "#             base_hh = z.groupby('zgpgroup_id').total_households.sum()\n",
      "#             base_ru = z.groupby('zgpgroup_id').total_residential_units.sum()\n",
      "#             base_nr = z.groupby('zgpgroup_id').total_nonresidential_sqft.sum()\n",
      "#             base_pop = z.groupby('zgpgroup_id').total_persons.sum()\n",
      "#             base_emp_zone = z.total_employment.copy()\n",
      "#             base_pop_zone = z.total_persons.copy()\n",
      "        \n",
      "        ##Estimate REPM instead of loading from CSV because it is so fast\n",
      "#         if sim_year==first_year:\n",
      "#             buildings = dset.fetch('buildings')\n",
      "#             buildings = buildings[buildings.estim_index==1]\n",
      "#             output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic-%s.csv\",\"PARIS HEDONIC MODEL (%s)\",\"price_%s\",\"price\"]\n",
      "#             ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "#                          'employment_density','tax_on_professionals','tco',]\n",
      "#             segments = buildings.groupby('building_type_id')\n",
      "#             for name, segment in segments:\n",
      "#                 if name == 1:\n",
      "#                     indvars = ind_vars1\n",
      "#                 if name == 2:\n",
      "#                     indvars = ind_vars2\n",
      "#                 if name == 3:\n",
      "#                     indvars = ind_vars3\n",
      "#                 if name == 4:\n",
      "#                     indvars = ind_vars4\n",
      "#                 if name == 6:\n",
      "#                     indvars = ind_vars6\n",
      "#                 est_data = pd.DataFrame(index=segment.index)\n",
      "#                 for varname in indvars:\n",
      "#                     est_data[varname] = segment[varname]\n",
      "#                 est_data = est_data.fillna(0)\n",
      "#                 est_data = sm.add_constant(est_data,prepend=False)\n",
      "#                 tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "#                 #print tmp_coeffname\n",
      "#                 depvar = segment['price'].apply(np.log)\n",
      "#                 print \"Estimating hedonic for %s with %d observations\" % (name,len(segment.index))\n",
      "#                 #print est_data.describe()\n",
      "#                 model = sm.OLS(depvar,est_data)\n",
      "#                 results = model.fit()\n",
      "#                 #print results.summary()\n",
      "#                 tmp_outcsv = output_csv%name\n",
      "#                 tmp_outtitle = output_title%name\n",
      "#                 misc.resultstocsv((results.rsquared,results.rsquared_adj),est_data.columns,\n",
      "#                                     zip(results.params,results.bse,results.tvalues),tmp_outcsv,hedonic=1,\n",
      "#                                     tblname=output_title)\n",
      "#                 dset.store_coeff(tmp_coeffname,results.params.values,results.params.index)\n",
      "                \n",
      "#             ##Load location choice model coefficients from csv or hdf5\n",
      "#             output_dir = os.path.join(os.environ['DATA_HOME'],'output')\n",
      "#             output_dir = os.path.join(output_dir, 'for_runs')\n",
      "#             coeff_store_path = os.path.join(output_dir,'coeffs.h5')\n",
      "#             coeff_store = pd.HDFStore(coeff_store_path)\n",
      "#             dset.coeffs = coeff_store.coeffs.copy()\n",
      "#             coeff_store.close()\n",
      "#             hh_submodels = ['hh_location_1', 'hh_location_2', 'hh_location_3', 'hh_location_4']\n",
      "#             for name in hh_submodels:\n",
      "#                 if name == 'hh_location_3':\n",
      "#                     colname1 = (name,'coeffs')\n",
      "#                     colname2 = (name,'fnames')\n",
      "#                     fnames =  dset.coeffs[colname2].append(pd.Series(['not_paris_subway_stations_x_1car', 'not_paris_subway_stations_x_2pluscar'],index=[48,49]))\n",
      "#                     coeffs =  dset.coeffs[colname1].append(pd.Series([0.0997, 0.0997],index=[48,49]))\n",
      "#                     dset.store_coeff(name,coeffs.values,fnames.values)\n",
      "#                 if name == 'hh_location_1':\n",
      "#                     colname1 = (name,'coeffs')\n",
      "#                     colname2 = (name,'fnames')\n",
      "#                     fnames =  dset.coeffs[colname2].append(pd.Series(['not_paris_subway_stations_x_1car', 'not_paris_subway_stations_x_2pluscar'],index=[48,49]))\n",
      "#                     coeffs =  dset.coeffs[colname1].append(pd.Series([0.0593, 0.0593],index=[48,49]))\n",
      "#                     dset.store_coeff(name,coeffs.values,fnames.values)\n",
      "#                 if name == 'hh_location_2':\n",
      "#                     dset.coeffs[(name,'fnames')][46] = 'not_paris_subway_stations_x_1car'\n",
      "#                     dset.coeffs[(name,'fnames')][47] = 'not_paris_subway_stations_x_2pluscar'\n",
      "#                     dset.coeffs[(name,'coeffs')][46] = 0.0380\n",
      "#                     dset.coeffs[(name,'coeffs')][47] = 0.0380\n",
      "#                 if name == 'hh_location_4':\n",
      "#                     dset.coeffs[(name,'fnames')][47] = 'not_paris_subway_stations_x_1car'\n",
      "#                     dset.coeffs[(name,'coeffs')][47] = 0.0277\n",
      "#                     dset.coeffs[(name,'fnames')][48] = 'not_paris_subway_stations_x_2pluscar'\n",
      "#                     dset.coeffs[(name,'coeffs')][48] = 0.0277\n",
      "                    \n",
      "#     ############     SCHEDULED DEVELOPMENT EVENTS\n",
      "#         if scenario == 'baseline':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_baseline')\n",
      "#         if scenario == 'low_impact':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_low_impact')\n",
      "#         if scenario == 'scen0':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_scen0')\n",
      "#         scheduled_nonres_sqft = sched_events[(sched_events.amount>0)*(sched_events.year==sim_year)*(sched_events.attribute=='non_residential_sqft')]\n",
      "#         print 'Added %s scheduled non-residential projects.' % len(scheduled_nonres_sqft.index)\n",
      "#         if len(scheduled_nonres_sqft.index)>0:\n",
      "#             scheduled_nonres_sqft = scheduled_nonres_sqft.reset_index().groupby('building_id').amount.sum()\n",
      "#             dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,scheduled_nonres_sqft.index)] = dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,scheduled_nonres_sqft.index)] + scheduled_nonres_sqft\n",
      "#         scheduled_resunits = sched_events[(sched_events.amount>0)*(sched_events.year==sim_year)*(sched_events.attribute=='residential_units')]\n",
      "#         print 'Added %s scheduled residential projects.' % len(scheduled_resunits.index)\n",
      "#         if len(scheduled_resunits.index)>0:\n",
      "#             scheduled_resunits = scheduled_resunits.reset_index().groupby('building_id').amount.sum()\n",
      "#             dset.buildings.residential_units[np.in1d(dset.buildings.index,scheduled_resunits.index)] = dset.buildings.residential_units[np.in1d(dset.buildings.index,scheduled_resunits.index)] + scheduled_resunits\n",
      "\n",
      "\n",
      "    ############     ELCM\n",
      "#         output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-elcm-%s.csv\",\"DRCOG EMPLOYMENT LOCATION CHOICE MODELS (%s)\",\"emp_location_%s\",\"establishment_building_ids\")\n",
      "#         dset.establishments['home_based_status']=0\n",
      "#         if scenario == 'baseline':\n",
      "#             new_jobs = {\"table\": \"dset.establishments\",\"writetotmp\": \"establishments\",\"model\": \"transitionmodel\",\"first_year\": 2010,\"control_totals\": \"dset.annual_employment_control_totals\",\n",
      "#                         \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_jobs\",\"size_field\":\"employees\"}\n",
      "#         import synthicity.urbansim.transitionmodel as transitionmodel\n",
      "#         transitionmodel.simulate(dset,new_jobs,year=sim_year,show=True)\n",
      "#         year = sim_year\n",
      "#         choosers = dset.fetch('establishments')\n",
      "#         depvar = 'building_id'\n",
      "#     #     rate_table = dset.annual_job_relocation_rates\n",
      "#     #     rate_table = rate_table*.1\n",
      "#     #     rate_field = \"job_relocation_probability\"\n",
      "#     #     movers = dset.relocation_rates(choosers,rate_table,rate_field)\n",
      "#     #     choosers[depvar].ix[movers] = -1\n",
      "#         movers = choosers[choosers[depvar]==-1]\n",
      "#         print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "#         alternatives = dset.buildings[(dset.buildings.non_residential_sqft>0)]\n",
      "#         alternatives['job_spaces'] = alternatives.non_residential_sqft/alternatives.building_sqft_per_job\n",
      "#         empty_units = alternatives.job_spaces.sub(choosers.groupby('building_id').employees.sum(),fill_value=0).astype('int')\n",
      "#         alts = alternatives.ix[empty_units.index]\n",
      "#         alts[\"supply\"] = empty_units\n",
      "#         lotterychoices = True\n",
      "#         pdf = pd.DataFrame(index=alts.index)\n",
      "#         segments = movers.groupby(['sector_id_six',])\n",
      "        \n",
      "#         ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "#         ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "#         ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "#         ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "#         ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "#         ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        \n",
      "#         for name, segment in segments:\n",
      "#             if name == 1:\n",
      "#                 ind_vars = ind_vars1 \n",
      "#             if name == 2:\n",
      "#                 ind_vars = ind_vars2\n",
      "#             if name == 3:\n",
      "#                 ind_vars = ind_vars3\n",
      "#             if name == 4:\n",
      "#                 ind_vars = ind_vars4\n",
      "#             if name == 5:\n",
      "#                 ind_vars = ind_vars5\n",
      "#             if name == 6:\n",
      "#                 ind_vars = ind_vars6\n",
      "             \n",
      "#             segment = segment.head(1)\n",
      "#             name_coeff= str(name)\n",
      "#             name = str(name)\n",
      "#             tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name_coeff\n",
      "#             SAMPLE_SIZE = alts.index.size \n",
      "#             numchoosers = segment.shape[0]\n",
      "#             numalts = alts.shape[0]\n",
      "#             sample = np.tile(alts.index.values,numchoosers)\n",
      "#             alts_sample = alts #sample#alternatives\n",
      "#             alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "#             alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "#             chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "#             chosen[:,0] = 1\n",
      "#             sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "# #             alternative_sample['ln_nonres_price_x_more_than_10_employees'] = (alternative_sample.ln_average_nonres_price6*alternative_sample.more_than_10_employees)\n",
      "#             est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "#             for varname in ind_vars:\n",
      "#                 est_data[varname] = alternative_sample[varname]\n",
      "#             est_data = est_data.fillna(0)\n",
      "#             data = est_data\n",
      "#             data = data.as_matrix()\n",
      "#             coeff = dset.load_coeff(tmp_coeffname)\n",
      "#             probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "#             pdf['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "                \n",
      "#         new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "#         mask = np.zeros(len(alts.index),dtype='bool')\n",
      "        \n",
      "#         for name, segment in segments:\n",
      "#             name = str(name)\n",
      "#             print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "#             p=pdf['segment%s'%name].values\n",
      "#             #p=pdf['segment%s'%name].values\n",
      "#             def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "#                 p = copy.copy(p)\n",
      "#                 p[alternatives.supply<minsize] = 0\n",
      "#                 #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "#                 try: \n",
      "#                   indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "#                 except:\n",
      "#                   print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "#                   return mask,new_homes\n",
      "#                 new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "#                 alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "#                 return mask,new_homes\n",
      "#             tmp = segment['employees']\n",
      "#             #tmp /= 100.0 ##If scaling demand amount is desired\n",
      "#             for name, subsegment in reversed(list(segment.groupby(tmp.astype('int')))):\n",
      "#                 #print \"Running subsegment with size = %s, num agents = %d\" % (name, len(subsegment.index))\n",
      "#                 mask,new_homes = choose(p,mask,alts,subsegment,new_homes,minsize=int(name))\n",
      "        \n",
      "#         build_cnts = new_homes.value_counts()  #num estabs place in each building\n",
      "#         print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "#         table = dset.establishments # need to go back to the whole dataset\n",
      "#         table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "#         dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        \n",
      "        \n",
      "    #################     HLCM\n",
      "#         output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-hlcm-%s.csv\",\"DRCOG HOUSEHOLD LOCATION CHOICE MODELS (%s)\",\"hh_location_%s\",\"household_building_ids\")\n",
      "#         if scenario == 'baseline':\n",
      "#             new_hhlds = {\"table\": \"dset.households\",\"writetotmp\": \"households\",\"model\": \"transitionmodel\",\"first_year\": 2010,\"control_totals\": \"dset.annual_household_control_totals\",\n",
      "#                          \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_households\"}\n",
      "#         import synthicity.urbansim.transitionmodel as transitionmodel\n",
      "#         transitionmodel.simulate(dset,new_hhlds,year=sim_year,show=True,subtract=True)\n",
      "#         year = sim_year\n",
      "#         choosers = dset.fetch('households')\n",
      "#         depvar = 'building_id'\n",
      "#         rate_table = dset.annual_household_relocation_rates\n",
      "#         rate_field = \"probability_of_relocating\"\n",
      "#         rate_table[rate_field] = rate_table[rate_field]*.1\n",
      "#         print rate_table\n",
      "#         movers = dset.relocation_rates(choosers,rate_table,rate_field)\n",
      "#         choosers[depvar].ix[movers] = -1\n",
      "#         movers = choosers[choosers[depvar]==-1]\n",
      "#         print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "#         alternatives = dset.buildings[(dset.buildings.residential_units>0)]\n",
      "#         empty_units = dset.buildings[(dset.buildings.residential_units>0)].residential_units.sub(choosers.groupby('building_id').size(),fill_value=0)\n",
      "#         empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "#         alternatives = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "#         alts1 = alternatives[alternatives.building_type_id==1]\n",
      "#         alts2 = alternatives[alternatives.building_type_id==2]\n",
      "#         alts3 = alternatives[alternatives.building_type_id==3]\n",
      "#         alts4 = alternatives[alternatives.building_type_id==4]\n",
      "#         pdf1 = pd.DataFrame(index=alts1.index)\n",
      "#         pdf2 = pd.DataFrame(index=alts2.index) \n",
      "#         pdf3 = pd.DataFrame(index=alts3.index)\n",
      "#         pdf4 = pd.DataFrame(index=alts4.index)\n",
      "        \n",
      "#         #segments = movers.groupby(['btype_tenure',])\n",
      "#         #choosers.groupby(['btype_tenure','income_cat','age_cat','sex_of_head'])\n",
      "#         segments = choosers.groupby(['btype',])\n",
      "        \n",
      "#         ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "#         ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "#         ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "#         ind_vars4=['residential_units_zone','non_residential_sqft_zone','unit_price_residential','in_denver',] \n",
      "    \n",
      "#         for name, segment in segments:\n",
      "#             #if type(name) is np.int64:  name = (name,0)\n",
      "#             if name == 1:\n",
      "#                 alts = alts1\n",
      "#                 ind_vars = ind_vars1\n",
      "#             if name == 2:\n",
      "#                 alts = alts2\n",
      "#                 ind_vars = ind_vars2\n",
      "#             if name == 3:\n",
      "#                 alts = alts3\n",
      "#                 ind_vars = ind_vars3\n",
      "#             if name == 4:\n",
      "#                 alts = alts4\n",
      "#                 ind_vars = ind_vars4\n",
      "#             segment = segment.head(1)\n",
      "#             name_coeff = str(name)\n",
      "#             name = str(name)\n",
      "#             tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name_coeff\n",
      "#             SAMPLE_SIZE = alts.index.size \n",
      "#             numchoosers = segment.shape[0]\n",
      "#             numalts = alts.shape[0]\n",
      "#             sample = np.tile(alts.index.values,numchoosers)\n",
      "#             alts_sample = alts #sample#alternatives\n",
      "#             alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "#             alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "#             chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "#             chosen[:,0] = 1\n",
      "#             sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "# #             alternative_sample['high_inc_x_percent_high_inc'] = (alternative_sample.high_inc*alternative_sample.percent_high_income)\n",
      "#             #alternative_sample['same_dpt_as_previous'] = (alternative_sample.previous_dpt==alternative_sample.dept_id).astype('int32')\n",
      "# #             if int(name_coeff)==1:\n",
      "# #                 alternative_sample['ln_price1_x_low_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.low_inc)\n",
      "# #                 alternative_sample['ln_price1_x_mid_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.mid_inc)\n",
      "# #                 alternative_sample['ln_price1_x_high_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.high_inc)\n",
      "#             est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "#             for varname in ind_vars:\n",
      "#                 est_data[varname] = alternative_sample[varname]\n",
      "#             est_data = est_data.fillna(0)\n",
      "#             data = est_data\n",
      "#             data = data.as_matrix()\n",
      "#             coeff = dset.load_coeff(tmp_coeffname)\n",
      "#             probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "#             if int(name_coeff) == 1:\n",
      "#                 pdf1['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index)  \n",
      "#             if int(name_coeff) == 2:\n",
      "#                 pdf2['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "#             if int(name_coeff) == 3:\n",
      "#                 pdf3['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "#             if int(name_coeff) == 4:\n",
      "#                 pdf4['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "     \n",
      "#         new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "#         #mask = np.zeros(len(alternatives.index),dtype='bool')\n",
      "#         for name, segment in segments:\n",
      "# #             if type(name) is np.int64:  name = (name,0)\n",
      "# #             name_coeff = str(name[0])\n",
      "#             name_coeff = str(name)\n",
      "#             name = str(name)\n",
      "#             if int(name_coeff) == 1:\n",
      "#                 p=pdf1['segment%s'%name].values\n",
      "#                 mask = np.zeros(len(alts1.index),dtype='bool')\n",
      "#             if int(name_coeff) == 2:\n",
      "#                 p=pdf2['segment%s'%name].values \n",
      "#                 mask = np.zeros(len(alts2.index),dtype='bool')\n",
      "#             if int(name_coeff) == 3:\n",
      "#                 p=pdf3['segment%s'%name].values \n",
      "#                 mask = np.zeros(len(alts3.index),dtype='bool')\n",
      "#             if int(name_coeff) == 4:\n",
      "#                 p=pdf4['segment%s'%name].values\n",
      "#                 mask = np.zeros(len(alts4.index),dtype='bool')\n",
      "#             print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "#             #p=pdf['segment%s'%name].values\n",
      "         \n",
      "#             def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "#                 p = copy.copy(p)\n",
      "#                 p[mask] = 0 # already chosen\n",
      "#                 #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "#                 try: \n",
      "#                   indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "#                 except:\n",
      "#                   print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "#                   return mask,new_homes\n",
      "#                 new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "#                 mask[indexes] = 1\n",
      "              \n",
      "#                 return mask,new_homes\n",
      "#             if int(name_coeff) == 1:\n",
      "#                 mask,new_homes = choose(p,mask,alts1,segment,new_homes)\n",
      "#             if int(name_coeff) == 2:\n",
      "#                 mask,new_homes = choose(p,mask,alts2,segment,new_homes)\n",
      "#             if int(name_coeff) == 3:\n",
      "#                 mask,new_homes = choose(p,mask,alts3,segment,new_homes)\n",
      "#             if int(name_coeff) == 4:\n",
      "#                 mask,new_homes = choose(p,mask,alts4,segment,new_homes)\n",
      "            \n",
      "#         build_cnts = new_homes.value_counts()  #num households place in each building\n",
      "#         print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "#         table = dset.households # need to go back to the whole dataset\n",
      "#         table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "#         dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        \n",
      "        \n",
      "    #################     RDPLCM\n",
      "        target_vacancy1 = .081\n",
      "        target_vacancy2 = .081\n",
      "        target_vacancy3 = .081\n",
      "        target_vacancy4 = .081\n",
      "        target_vacancy6 = .097\n",
      "        target_vacancies = pd.Series([target_vacancy1,target_vacancy2,target_vacancy3,target_vacancy4,target_vacancy6],index=[1,2,3,4,6])\n",
      "        households_by_btype = dset.households.groupby('btype').building_id.count()\n",
      "        resunits_by_btype = dset.buildings[dset.buildings.building_type_id<5].groupby('btype').residential_units.sum()\n",
      "        vacant_resunits = resunits_by_btype - households_by_btype\n",
      "        vacant_resunits = vacant_resunits[vacant_resunits.index.values<6]\n",
      "        target_vacant_resunits = resunits_by_btype * target_vacancies\n",
      "        diff_resunits = np.round(target_vacant_resunits - vacant_resunits)\n",
      "        print 'Residential units by building type to construct:  '\n",
      "        building_type_ids = []\n",
      "        building_ids = []\n",
      "        for idx_btype in diff_resunits[diff_resunits>0].index:\n",
      "            building_type_id = idx_btype\n",
      "            residential_units_to_build = int(diff_resunits[idx_btype])\n",
      "            print building_type_id, residential_units_to_build\n",
      "            building_type_ids += [building_type_id]*residential_units_to_build\n",
      "            building_ids += [-1]*residential_units_to_build\n",
      "        building_type_ids = np.array(building_type_ids)\n",
      "        building_ids = np.array(building_ids)\n",
      "        residential_unit_ids = np.arange(len(building_ids))+1\n",
      "        residential_units = pd.DataFrame({'building_type_id':building_type_ids,'building_id':building_ids,'residential_unit_id':residential_unit_ids})\n",
      "        residential_units = residential_units.set_index('residential_unit_id')\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-dplcm-%s.csv\",\"DRCOG DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "        year = sim_year\n",
      "        choosers = residential_units\n",
      "        depvar = 'building_id'\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.residential_units_capacity>0)]\n",
      "#         alternatives.residential_units_capacity[alternatives.zgpgroup75==1] = np.round(alternatives.residential_units_capacity[alternatives.zgpgroup75==1]*.6)\n",
      "        empty_units = dset.buildings[(dset.buildings.residential_units_capacity>0)].residential_units_capacity.sub(dset.buildings.residential_units,fill_value=0)\n",
      "        empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "        empty_units[empty_units>2000] = 2000\n",
      "        ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "        ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "        ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "        ind_vars4=['residential_units_zone','non_residential_sqft_zone','unit_price_residential','in_denver',] \n",
      "#         indvars_together = ind_vars1 + ind_vars2 + ind_vars3 + ind_vars4 + ['building_type_id','zone_id','zgp_id','dept_id','residential_units','residential_units_capacity','non_residential_sqft','non_residential_sqft_capacity']\n",
      "#         columns_to_keep = np.unique(indvars_together)\n",
      "#         alternatives = alternatives[list(columns_to_keep)]\n",
      "        alternatives = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "        alts1 = alternatives[alternatives.btype==1]\n",
      "        alts2 = alternatives[alternatives.btype==2]\n",
      "        alts3 = alternatives[alternatives.btype==3]\n",
      "        alts4 = alternatives[alternatives.btype==4]\n",
      "        \n",
      "        segments = movers.groupby(['type',])\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            if name == 1:\n",
      "                alts = alts1\n",
      "                ind_vars = ind_vars1\n",
      "                pdf1 = pd.DataFrame(index=alts1.index) \n",
      "            if name == 2:\n",
      "                alts = alts2\n",
      "                ind_vars = ind_vars2\n",
      "                pdf2 = pd.DataFrame(index=alts2.index) \n",
      "            if name == 3:\n",
      "                alts = alts3\n",
      "                ind_vars = ind_vars3\n",
      "                pdf3 = pd.DataFrame(index=alts3.index) \n",
      "            if name == 4:\n",
      "                alts = alts4\n",
      "                ind_vars = ind_vars4\n",
      "                pdf4 = pd.DataFrame(index=alts4.index) \n",
      "            \n",
      "            segment = segment.head(1)\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            if int(name) == 1:\n",
      "                pdf1['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index)  \n",
      "            if int(name) == 2:\n",
      "                pdf2['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name) == 3:\n",
      "                pdf3['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name) == 4:\n",
      "                pdf4['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "     \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        #mask = np.zeros(len(alternatives.index),dtype='bool')\n",
      "        for name, segment in segments:\n",
      "            name = str(name)\n",
      "            if int(name) == 1:\n",
      "                p=pdf1['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts1.index),dtype='bool')\n",
      "            if int(name) == 2:\n",
      "                p=pdf2['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts2.index),dtype='bool')\n",
      "            if int(name) == 3:\n",
      "                p=pdf3['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts3.index),dtype='bool')\n",
      "            if int(name) == 4:\n",
      "                p=pdf4['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts4.index),dtype='bool')\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "            #p=pdf['segment%s'%name].values\n",
      "         \n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                if minsize is not None: p[alternatives.supply<minsize] = 0\n",
      "                else: p[mask] = 0 # already chosen\n",
      "    #             print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "            \n",
      "                if minsize is not None: alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "                else: mask[indexes] = 1\n",
      "              \n",
      "                return mask,new_homes\n",
      "            if int(name) == 1:\n",
      "                mask,new_homes = choose(p,mask,alts1,segment,new_homes)\n",
      "            if int(name) == 2:\n",
      "                mask,new_homes = choose(p,mask,alts2,segment,new_homes)\n",
      "            if int(name) == 3:\n",
      "                mask,new_homes = choose(p,mask,alts3,segment,new_homes)\n",
      "            if int(name) == 4:\n",
      "                mask,new_homes = choose(p,mask,alts4,segment,new_homes)\n",
      "            \n",
      "        build_cnts = new_homes.value_counts()  #num resunits place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = residential_units # need to go back to the whole dataset *****************\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        new_res_construction_totals = residential_units.groupby('building_id').size()\n",
      "        print 'Previous residential unit total:'\n",
      "        print dset.buildings.residential_units.sum()\n",
      "        dset.buildings.residential_units[np.in1d(dset.buildings.index,new_res_construction_totals.index)] = dset.buildings.residential_units[np.in1d(dset.buildings.index,new_res_construction_totals.index)] + new_res_construction_totals\n",
      "        print 'Current residential unit total:'\n",
      "        print dset.buildings.residential_units.sum()\n",
      "        \n",
      "        \n",
      "    #################     NRDPLCM\n",
      "        target_vacancy6 = .147\n",
      "        employment_by_building = dset.establishments.groupby('building_id').employees.sum()\n",
      "        bsqft_job = dset.buildings[dset.buildings.btype==6].building_sqft_per_job\n",
      "        occupied_nonres_sqft = employment_by_building*bsqft_job\n",
      "        total_occupied_nonres_sqft = occupied_nonres_sqft.sum()\n",
      "        total_nonres_sqft = dset.buildings.non_residential_sqft.sum()\n",
      "        vacant_nonres_sqft = total_nonres_sqft - total_occupied_nonres_sqft\n",
      "        target_vacant_nonres_sqft = total_nonres_sqft*target_vacancy6\n",
      "        nonres_sqft_to_build = target_vacant_nonres_sqft - vacant_nonres_sqft\n",
      "        print 'Non-residential sqft to construct:  '\n",
      "        print nonres_sqft_to_build\n",
      "        nonres_units_to_build = int(round(nonres_sqft_to_build/500.0))\n",
      "        print 'Non-residential units to construct:  '\n",
      "        print nonres_units_to_build\n",
      "        building_type_ids = [6]*nonres_units_to_build\n",
      "        nonres_building_ids = [-1]*nonres_units_to_build\n",
      "        building_type_ids = np.array(building_type_ids)\n",
      "        nonres_building_ids = np.array(nonres_building_ids)\n",
      "        nonres_unit_ids = np.arange(len(nonres_building_ids))+1\n",
      "        nonres_units = pd.DataFrame({'building_type_id':building_type_ids,'building_id':nonres_building_ids,'nonres_unit_id':nonres_unit_ids})\n",
      "        nonres_units = nonres_units.set_index('nonres_unit_id')\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"paris-coeff-dplcm-%s.csv\",\"PARIS DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "        year = sim_year\n",
      "        choosers = nonres_units\n",
      "        depvar = 'building_id'\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.non_residential_sqft_capacity>0)*(dset.buildings.zgpgroup75!=1)]\n",
      "        alternatives['nonres_units'] = alternatives.non_residential_sqft/500\n",
      "        alternatives['nonres_units_capacity'] = alternatives.non_residential_sqft_capacity/500\n",
      "        empty_units = alternatives.nonres_units_capacity.sub(alternatives.nonres_units,fill_value=0)\n",
      "        empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "        empty_units[empty_units>2500] = 2500\n",
      "        ind_vars6=['in_la_defense','in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpraft90','percent_hh_one_worker','percent_hh_twoplus_workers','cprbef15','percent_foreigners','percent_young','percent_old',\n",
      "                   'percent_hhsize2', 'percent_hhsize3plus','employment_density','population_density','vpo'\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        indvars_together = ind_vars6 + ['building_type_id','zone_id','zgp_id','dept_id','residential_units','residential_units_capacity','non_residential_sqft','non_residential_sqft_capacity']\n",
      "        columns_to_keep = np.unique(indvars_together)\n",
      "        alternatives = alternatives[list(columns_to_keep)]\n",
      "        alts6 = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "        \n",
      "        segments = movers.groupby(['btype',])\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            if name == 6:\n",
      "                alts = alts6\n",
      "                ind_vars = ind_vars6\n",
      "                pdf6 = pd.DataFrame(index=alts.index) \n",
      "            \n",
      "            segment = segment.head(1)\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            if int(name) == 6:\n",
      "                pdf6['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        for name, segment in segments:\n",
      "            name = str(name)\n",
      "            if int(name) == 6:\n",
      "                p=pdf6['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts6.index),dtype='bool')\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "         \n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                if minsize is not None: p[alternatives.supply<minsize] = 0\n",
      "                else: p[mask] = 0 # already chosen\n",
      "                #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "        \n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "            \n",
      "                if minsize is not None: alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "                else: mask[indexes] = 1\n",
      "              \n",
      "                return mask,new_homes\n",
      "            if int(name) == 6:\n",
      "                mask,new_homes = choose(p,mask,alts6,segment,new_homes)\n",
      "            \n",
      "        build_cnts = new_homes.value_counts()  #num resunits place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = nonres_units # need to go back to the whole dataset *****************\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr('nr'+output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        new_nonres_construction_totals = table.groupby('building_id').size()*500\n",
      "        print 'Previous non-residential sqft total:'\n",
      "        print dset.buildings.non_residential_sqft.sum()\n",
      "        dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,new_nonres_construction_totals.index)] = dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,new_nonres_construction_totals.index)] + new_nonres_construction_totals\n",
      "        print 'Current non-residential sqft total:'\n",
      "        print dset.buildings.non_residential_sqft.sum()\n",
      "    \n",
      "    \n",
      "    #################     REPM\n",
      "        year = sim_year\n",
      "        buildings = dset.fetch('buildings')\n",
      "        output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic.csv\",\"PARIS HEDONIC MODEL\",\"price_%s\",\"price\"]\n",
      "        ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "                     'employment_density','tax_on_professionals','tco',]\n",
      "        simrents = []\n",
      "        segments = buildings.groupby('building_type_id')\n",
      "        for name, segment in segments:\n",
      "            if name == 1:\n",
      "                indvars = ind_vars1\n",
      "            if name == 2:\n",
      "                indvars = ind_vars2\n",
      "            if name == 3:\n",
      "                indvars = ind_vars3\n",
      "            if name == 4:\n",
      "                indvars = ind_vars4\n",
      "            if name == 6:\n",
      "                indvars = ind_vars6\n",
      "            est_data = pd.DataFrame(index=segment.index)\n",
      "            for varname in indvars:\n",
      "                est_data[varname] = segment[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            est_data = sm.add_constant(est_data,prepend=False)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            print \"Generating rents on %d buildings\" % (est_data.shape[0])\n",
      "            vec = dset.load_coeff(tmp_coeffname)\n",
      "            vec = np.reshape(vec,(vec.size,1))\n",
      "            rents = est_data.dot(vec).astype('f4')\n",
      "            rents = rents.apply(np.exp)\n",
      "            simrents.append(rents[rents.columns[0]])\n",
      "            \n",
      "        simrents = pd.concat(simrents)\n",
      "        dset.buildings[output_varname] = simrents.reindex(dset.buildings.index)\n",
      "        dset.store_attr(output_varname,year,simrents)\n",
      "        \n",
      "    #######ANNUAL SUMMARY\n",
      "        b = dset.fetch('buildings')\n",
      "        e = dset.fetch('establishments')\n",
      "        hh = dset.fetch('households')\n",
      "        summary['employment'].append(e[e.building_id>0].employees.sum())\n",
      "        summary['households'].append(len(hh[hh.building_id>0].building_id))\n",
      "        summary['non_residential_sqft'].append(b.non_residential_sqft.sum())\n",
      "        summary['residential_units'].append(b.residential_units.sum())\n",
      "        summary['price'].append(b.price.mean())\n",
      "        \n",
      "        ##End-of-iteration calibration update\n",
      "        if sim_year == last_year:\n",
      "            print summary\n",
      "            hh['zone_id'] = b.zone_id[hh.building_id].values\n",
      "            e['zone_id'] = b.zone_id[e.building_id].values\n",
      "            z['total_households'] = hh.groupby('zone_id').building_id.count()\n",
      "            z['total_residential_units'] = b.groupby('zone_id').residential_units.sum()\n",
      "            z['total_nonresidential_sqft'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "            z['total_employment'] = e.groupby('zone_id').employees.sum()\n",
      "            z['total_persons'] = hh.groupby('zone_id').persons.sum()\n",
      "            sim_pop = z.groupby('zgpgroup_id').total_persons.sum()\n",
      "            sim_emp = z.groupby('zgpgroup_id').total_employment.sum()\n",
      "            sim_hh = z.groupby('zgpgroup_id').total_households.sum()\n",
      "            sim_ru = z.groupby('zgpgroup_id').total_residential_units.sum()\n",
      "            sim_nr = z.groupby('zgpgroup_id').total_nonresidential_sqft.sum()\n",
      "            \n",
      "            emp_diff_zone = z.total_employment - base_emp_zone\n",
      "            pop_diff_zone = z.total_persons - base_pop_zone\n",
      "            zone_diffs = pd.DataFrame({'emp_diff':emp_diff_zone,'pop_diff':pop_diff_zone})\n",
      "            \n",
      "            pop_diff = sim_pop - base_pop\n",
      "            emp_diff = sim_emp - base_emp\n",
      "            hh_diff = sim_hh - base_hh\n",
      "            ru_diff = sim_ru - base_ru\n",
      "            nr_diff = sim_nr - base_nr\n",
      "            print 'Employment in 2035, by ZGPGroup'\n",
      "            print sim_emp\n",
      "            print 'Households in 2035, by ZGPGroup'\n",
      "            print sim_hh\n",
      "            print 'Population in 2035, by ZGPGroup'\n",
      "            print sim_pop\n",
      "            print 'Residential units in 2035, by ZGPGroup'\n",
      "            print sim_ru\n",
      "            print 'Non-residential sqft in 2035 by ZGPGroup'\n",
      "            print sim_nr\n",
      "            print 'Employment growth 1999-2035, by ZGPGroup'\n",
      "            print emp_diff\n",
      "            print 'Household growth 1999-2035, by ZGPGroup'\n",
      "            print hh_diff\n",
      "            print 'Population growth 1999-2035, by ZGPGroup'\n",
      "            print pop_diff\n",
      "            print 'Residential unit growth 1999-2035, by ZGPGroup'\n",
      "            print ru_diff\n",
      "            print 'Non-residential sqft growth 1999-2035 by ZGPGroup'\n",
      "            print nr_diff\n",
      "            \n",
      "            prop_growth_emp = emp_diff*1.0/emp_diff.sum()\n",
      "            prop_growth_hh = hh_diff*1.0/hh_diff.sum()\n",
      "            prop_growth_pop = pop_diff*1.0/pop_diff.sum()\n",
      "            prop_growth_ru = ru_diff*1.0/ru_diff.sum()\n",
      "            prop_growth_nr = nr_diff*1.0/nr_diff.sum()\n",
      "            perc_growth_hh = (hh_diff)*100.0/base_hh\n",
      "            perc_growth_pop = (pop_diff)*100.0/base_pop\n",
      "            perc_growth_emp = (emp_diff)*100.0/base_emp\n",
      "            perc_growth_ru = (ru_diff)*100.0/base_ru\n",
      "            perc_growth_nr = (nr_diff)*100.0/base_nr\n",
      "            print 'Proportion of employment growth captured by ZGPGroup'\n",
      "            print prop_growth_emp\n",
      "            print 'Proportion of household growth captured by ZGPGroup'\n",
      "            print prop_growth_hh\n",
      "            print 'Proportion of population growth captured by ZGPGroup'\n",
      "            print prop_growth_pop\n",
      "            print 'Proportion of residential unit growth captured by ZGPGroup'\n",
      "            print prop_growth_ru\n",
      "            print 'Proportion of non-residential sqft growth captured by ZGPGroup'\n",
      "            print prop_growth_nr\n",
      "            \n",
      "            print 'Percent employment growth, ZGPGroup'\n",
      "            print perc_growth_emp\n",
      "            print 'Perrcent household growth, ZGPGroup'\n",
      "            print perc_growth_hh\n",
      "            print 'Percent population growth, ZGPGroup'\n",
      "            print perc_growth_pop\n",
      "            print 'Percent residential unit growth, ZGPGroup'\n",
      "            print perc_growth_ru\n",
      "            print 'Percent non-residential sqft growth, ZGPGroup'\n",
      "            print perc_growth_nr\n",
      "            \n",
      "            population = pd.DataFrame({'simulated_amount':sim_pop,'difference':pop_diff,'proportion_captured':prop_growth_pop})\n",
      "            employment = pd.DataFrame({'simulated_amount':sim_emp,'difference':emp_diff,'proportion_captured':prop_growth_emp})\n",
      "            household = pd.DataFrame({'simulated_amount':sim_hh,'difference':hh_diff,'proportion_captured':prop_growth_hh})\n",
      "            residential_unit = pd.DataFrame({'simulated_amount':sim_ru,'difference':ru_diff,'proportion_captured':prop_growth_ru})\n",
      "            nonres_sqft = pd.DataFrame({'simulated_amount':sim_nr,'difference':nr_diff,'proportion_captured':prop_growth_nr})\n",
      "            \n",
      "            population.to_csv(output_dir + '\\\\' + scenario+ title + '_population.csv')\n",
      "            employment.to_csv(output_dir + '\\\\' + scenario+ title + '_employment.csv')\n",
      "            household.to_csv(output_dir + '\\\\' + scenario+ title + '_households.csv')\n",
      "            residential_unit.to_csv(output_dir + '\\\\' + scenario+ title + '_residential_units.csv')\n",
      "            nonres_sqft.to_csv(output_dir + '\\\\' + scenario+ title + '_nonresidential_sqft.csv')\n",
      "            \n",
      "            zone_diffs.to_csv(output_dir + '\\\\' + scenario + title + '_zone_diffs.csv')\n",
      "            \n",
      "            estabs_base = dset.store.establishments\n",
      "            b = dset.fetch('buildings')\n",
      "            estabs_base['dept_id'] = b.dept_id[estabs_base.building_id].values\n",
      "            estabs_base_by_dept = estabs_base.groupby('dept_id').employees.sum()\n",
      "            estabs_sim = dset.fetch('establishments')\n",
      "            estabs_sim['dept_id'] = b.dept_id[estabs_sim.building_id].values\n",
      "            estabs_sim_by_dept = estabs_sim.groupby('dept_id').employees.sum()\n",
      "            print 'Dept Growth Rate, Employment'\n",
      "            print (estabs_sim_by_dept - estabs_base_by_dept)*1.0/estabs_base_by_dept \n",
      "            \n",
      "            hh_base = dset.store.households\n",
      "            b = dset.fetch('buildings')\n",
      "            hh_base['dept_id'] = b.dept_id[hh_base.building_id].values\n",
      "            hh_base_by_dept = hh_base.groupby('dept_id').building_id.count()\n",
      "            hh_sim = dset.fetch('households')\n",
      "            hh_sim['dept_id'] = b.dept_id[hh_sim.building_id].values\n",
      "            hh_sim_by_dept = hh_sim.groupby('dept_id').building_id.count()\n",
      "            print 'Dept Growth Rate, Households'\n",
      "            print (hh_sim_by_dept - hh_base_by_dept)*1.0/hh_base_by_dept\n",
      "            \n",
      "            z['resunits_base'] = dset.store.buildings.groupby('zone_id').residential_units.sum()\n",
      "            resunits_base_by_dept = z.groupby('dept_id').resunits_base.sum()\n",
      "            b = dset.fetch('buildings')\n",
      "            resunits_sim_by_dept = b.groupby('dept_id').residential_units.sum()\n",
      "            print 'Dept Growth Rate, Residential Units'\n",
      "            print (resunits_sim_by_dept - resunits_base_by_dept)*1.0/resunits_base_by_dept\n",
      "        \n",
      "            z['nonres_sqft_base'] = dset.store.buildings.groupby('zone_id').non_residential_sqft.sum()\n",
      "            nonres_sqft_base_by_dept = z.groupby('dept_id').nonres_sqft_base.sum()\n",
      "            b = dset.fetch('buildings')\n",
      "            nonres_sqft_sim_by_dept = b.groupby('dept_id').non_residential_sqft.sum()\n",
      "            print 'Dept Growth Rate, Non-residential sqft'\n",
      "            print (nonres_sqft_sim_by_dept - nonres_sqft_base_by_dept)*1.0/nonres_sqft_base_by_dept\n",
      "            \n",
      "            sim_store_path = os.path.join(output_dir,'sim_store.h5')\n",
      "            sim_store = pd.HDFStore(sim_store_path)\n",
      "            sim_store[scenario+ title + '_households'] = hh\n",
      "            sim_store[scenario+ title + '_establishments'] = e\n",
      "            sim_store[scenario+ title + '_buildings'] = b\n",
      "            sim_store.close()\n",
      "            \n",
      "    elapsed = time.time() - seconds_start\n",
      "    print \"TOTAL elapsed time: \" + str(elapsed) + \" seconds.\"\n",
      "    \n",
      "print 'Done running all three scenarios.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running scenario: baseline\n",
        "1389819138.21\n",
        "Simulating year 2010\n",
        "Residential units by building type to construct:  "
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dset.coeffs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}