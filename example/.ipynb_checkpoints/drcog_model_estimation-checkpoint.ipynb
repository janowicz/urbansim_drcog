{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Paris Model Estimation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variable Library"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd, os, statsmodels.api as sm\n",
      "import synthicity.urbansim.interaction as interaction\n",
      "from synthicity.utils import misc\n",
      "import dataset, copy, time\n",
      "dset = dataset.DRCOGDataset(os.path.join(misc.data_dir(),'drcog.h5'))\n",
      "#VARIABLE LIBRARY\n",
      "#parcel\n",
      "p = dset.fetch('parcels')\n",
      "p['in_denver'] = (p.county_id==8031).astype('int32')\n",
      "#building\n",
      "b = dset.fetch('buildings')\n",
      "b['zone_id'] = p.zone_id[b.parcel_id].values\n",
      "b['btype'] = 1*(b.building_type_id==2) + 2*(b.building_type_id==3) + 3*(b.building_type_id==20) + 4*(b.building_type_id==24) + 6*np.invert(np.in1d(b.building_type_id,[2,3,20,24]))\n",
      "#household\n",
      "hh_estim = dset.fetch('households_for_estimation')\n",
      "hh = dset.fetch('households')\n",
      "for table in [hh_estim, hh]:\n",
      "    choosers = table\n",
      "    choosers['building_type_id'] = b.building_type_id[choosers.building_id].values\n",
      "    choosers['btype'] = 1*(choosers.building_type_id==2) + 2*(choosers.building_type_id==3) + 3*(choosers.building_type_id==20) + 4*np.invert(np.in1d(choosers.building_type_id,[2,3,20]))\n",
      "#establishment\n",
      "e = dset.fetch('establishments')\n",
      "e['sector_id_six'] = 1*(e.sector_id==61) + 2*(e.sector_id==71) + 3*np.in1d(e.sector_id,[11,21,22,23,31,32,33,42,48,49]) + 4*np.in1d(e.sector_id,[7221,7222,7224]) + 5*np.in1d(e.sector_id,[44,45,7211,7212,7213,7223]) + 6*np.in1d(e.sector_id,[51,52,53,54,55,56,62,81,92])\n",
      "#zone\n",
      "z = dset.fetch('zones')\n",
      "z['residential_units_zone'] = b.groupby('zone_id').residential_units.sum()\n",
      "z['non_residential_sqft_zone'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "#merge parcels with zones\n",
      "pz = pd.merge(p,z,left_on='zone_id',right_index=True)\n",
      "#merge buildings with parcels/zones\n",
      "dset.d['buildings'] = pd.merge(b,pz,left_on='parcel_id',right_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching parcels\n",
        "Fetching modify_table\n",
        "Fetching buildings"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching establishments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching households_for_estimation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table\n",
        "Fetching households\n",
        "Fetching modify_table\n",
        "Fetching zones"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fetching modify_table\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Household Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'building_id'\n",
      "SAMPLE_SIZE=100\n",
      "choosers = dset.fetch('households_for_estimation')\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 10000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-hlcm-%s.csv\",\"DRCOG HOUSEHOLD LOCATION CHOICE MODELS (%s)\",\"hh_location_%s\",\"household_building_ids\")\n",
      "\n",
      "#alternatives = dset.buildings[(dset.buildings.residential_units>0)]\n",
      "alternatives = dset.buildings\n",
      "# alts1 = alternatives[alternatives.building_type_id==2]\n",
      "# alts2 = alternatives[alternatives.building_type_id==3]\n",
      "# alts3 = alternatives[alternatives.building_type_id==20]\n",
      "# alts4 = alternatives[alternatives.building_type_id==24]\n",
      "alts1 = alternatives\n",
      "alts2 = alternatives\n",
      "alts3 = alternatives\n",
      "alts4 = alternatives\n",
      "\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_residential','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','unit_price_residential','in_denver',] \n",
      "\n",
      "segments = choosers.groupby(['btype',])\n",
      "for name, segment in segments:\n",
      "    if name == 1:\n",
      "        alts = alts1\n",
      "        ind_vars = ind_vars1\n",
      "    if name == 2:\n",
      "        alts = alts2\n",
      "        ind_vars = ind_vars2\n",
      "    if name == 3:\n",
      "        alts = alts3\n",
      "        ind_vars = ind_vars3\n",
      "    if name == 4:\n",
      "        alts = alts4\n",
      "        ind_vars = ind_vars4\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.building_id) > 500: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 500,replace=False)]\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    #alternative_sample['high_inc_x_percent_high_inc'] = (alternative_sample.high_inc*alternative_sample.percent_high_income)\n",
      "    #alternative_sample['interaction_test2'] = (alternative_sample.low_inc*alternative_sample.mean_age_of_head)\n",
      "#     if int(name)==1:\n",
      "#         alternative_sample['ln_price1_x_low_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.low_inc)\n",
      "#     if int(name)==2:\n",
      "#         alternative_sample['ln_price2_x_low_income'] = (alternative_sample.ln_average_res_price2*alternative_sample.low_inc)\n",
      "#     if int(name)==3:\n",
      "#         alternative_sample['ln_price3_x_low_income'] = (alternative_sample.ln_average_res_price3*alternative_sample.low_inc)\n",
      "#     if int(name)==4:\n",
      "#         alternative_sample['ln_price4_x_low_income'] = (alternative_sample.ln_average_res_price4*alternative_sample.low_inc)\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "        try:\n",
      "            fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "            #print fit\n",
      "            #print results\n",
      "            fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "            print misc.resultstotable(fnames,results)\n",
      "            misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "            dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "        except:\n",
      "            print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimating parameters for segment = 1, size = 231\n",
        "Null Log-liklihood: -1063.794313"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -788.973161\n",
        "Log-liklihood ratio: 0.258340\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |  12.550 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   2.530 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.140 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |      -0.010 |      0 | -42.300 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 | -29.420 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.160 |   0.010 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 2, size = 162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -746.037570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -567.078171\n",
        "Log-liklihood ratio: 0.239880\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |  14.480 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   1.100 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.020 |   0.160 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |      -0.010 |      0 | -13.610 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |   2.100 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.210 |   0.010 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 3, size = 500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -2302.585093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -2280.790501\n",
        "Log-liklihood ratio: 0.009465\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   1.060 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  -2.200 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |  -1.380 | .            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |   6.490 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.110 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 4, size = 162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -746.037570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -736.321341\n",
        "Log-liklihood ratio: 0.013024\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   0.800 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   2.880 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|    unit price residential |           0 |      0 |  -3.040 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.170 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Establishment Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'building_id'\n",
      "SAMPLE_SIZE=50\n",
      "choosers = dset.fetch('establishments')\n",
      "choosers = choosers[(choosers.building_id>0)*(choosers.home_based_status==0)]\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 150000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-elcm-%s.csv\",\"DRCOG EMPLOYMENT LOCATION CHOICE MODELS (%s)\",\"emp_location_%s\",\"establishment_building_ids\")\n",
      "\n",
      "#alts = dset.buildings[(dset.buildings.non_residential_sqft>0)]\n",
      "alts = dset.buildings\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "segments = choosers.groupby(['sector_id_six',])\n",
      "for name, segment in segments:\n",
      "    print name\n",
      "    if name == 1:\n",
      "        ind_vars = ind_vars1 #interaction w/ employees\n",
      "    if name == 2:\n",
      "        ind_vars = ind_vars2 #big estabs are price sensitive\n",
      "    if name == 3:\n",
      "        ind_vars = ind_vars3 #negative price alone! yay!\n",
      "    if name == 4:\n",
      "        ind_vars = ind_vars4 #big estabs are price sensitive\n",
      "    if name == 5:\n",
      "        ind_vars = ind_vars5 #big estabs are price sensitive\n",
      "    if name == 6:\n",
      "        ind_vars = ind_vars6 #small estabs are price sensitive\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.building_id) > 6000: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 6000,replace=False)]\n",
      "    #sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar],weight_var='non_residential_sqft')\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    #alternative_sample['paris_x_employees'] = (alternative_sample.in_paris*alternative_sample.employees)\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "        try:\n",
      "            fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "            #print fit\n",
      "            #print results\n",
      "            fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "            print misc.resultstotable(fnames,results)\n",
      "            misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "            dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "        except:\n",
      "            print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "Estimating parameters for segment = 1, size = 3051"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -11935.582190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -11364.064640\n",
        "Log-liklihood ratio: 0.047884\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -19.330 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  30.540 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.060 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -13.140 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   6.210 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.050 |       0 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "2\n",
        "Estimating parameters for segment = 2, size = 1752"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -6853.864306"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -6454.514284\n",
        "Log-liklihood ratio: 0.058266\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -25.200 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  20.500 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.080 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 |  -3.080 | **           |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.890 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.060 |       0 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "3\n",
        "Estimating parameters for segment = 3, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -20725.562859\n",
        "Log-liklihood ratio: 0.117014\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -56.910 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  65.850 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.130 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -11.140 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.390 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "4\n",
        "Estimating parameters for segment = 4, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21400.457818\n",
        "Log-liklihood ratio: 0.088261\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -42.830 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  53.780 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |   0.120 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -49.070 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   1.670 | *            |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "5\n",
        "Estimating parameters for segment = 5, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21325.322818\n",
        "Log-liklihood ratio: 0.091462\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -45.600 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  64.290 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |  -0.260 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 | -29.030 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |  -0.040 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.020 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "6\n",
        "Estimating parameters for segment = 6, size = 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -23472.138033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -21611.178679\n",
        "Log-liklihood ratio: 0.079284\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables          | Coefficient | Stderr | T-score | Significance |\n",
        "+============================+=============+========+=========+==============+\n",
        "|     residential units zone |           0 |      0 | -39.130 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|  non residential sqft zone |           0 |      0 |  59.490 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|        allpurpose agglosum |           0 |      0 |   0.120 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                    acreage |           0 |      0 |     -34 | ***          |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "| unit price non residential |           0 |      0 |   0.220 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n",
        "|                  in denver |           0 |  0.030 |   0.010 |              |\n",
        "+----------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Development Project Location Choice Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "depvar = 'parcel_id'\n",
      "SAMPLE_SIZE=100\n",
      "choosers = dset.fetch('buildings')\n",
      "#p_nsqft = choosers.groupby('parcel_id').non_residential_sqft.sum()\n",
      "choosers = choosers[choosers.year_built>2000]\n",
      "#choosers = choosers.ix[np.random.choice(choosers.index, 150000,replace=False)]\n",
      "output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-dplcm-%s.csv\",\"DRCOG DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "\n",
      "alts = pd.merge(dset.parcels,dset.zones,left_on='zone_id',right_index=True)\n",
      "alts['capacity'] = alts.parcel_sqft\n",
      "# alts1 = alts[alts.building_type_id==1]\n",
      "# alts2 = alts[alts.building_type_id==2]\n",
      "# alts3 = alts[alts.building_type_id==3]\n",
      "# alts4 = alts[alts.building_type_id==4]\n",
      "# alts6 = alts[alts.building_type_id==6]\n",
      "alts1 = alts\n",
      "alts2 = alts\n",
      "alts3 = alts\n",
      "alts4 = alts\n",
      "alts6 = alts\n",
      "\n",
      "ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','in_denver',]\n",
      "\n",
      "segments = choosers.groupby(['btype',])\n",
      "for name, segment in segments:\n",
      "    if name == 1:\n",
      "        alts = alts1\n",
      "        ind_vars = ind_vars1\n",
      "    if name == 2:\n",
      "        alts = alts2\n",
      "        ind_vars = ind_vars2\n",
      "    if name == 3:\n",
      "        alts = alts3\n",
      "        ind_vars = ind_vars3\n",
      "    if name == 4:\n",
      "        alts = alts4\n",
      "        ind_vars = ind_vars4\n",
      "    if name == 6:\n",
      "        alts = alts6\n",
      "        ind_vars = ind_vars6\n",
      "    name = str(name)\n",
      "    tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "    if len(segment.parcel_id) > 1000: #reduce size of segment if too big so things don't bog down\n",
      "        segment = segment.ix[np.random.choice(segment.index, 1000,replace=False)]\n",
      "    sample, alternative_sample, est_params = interaction.mnl_interaction_dataset(segment,alts,SAMPLE_SIZE,chosenalts=segment[depvar])\n",
      "    print \"Estimating parameters for segment = %s, size = %d\" % (name, len(segment.index)) \n",
      "    if len(segment.index) > 50:\n",
      "        est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "        for varname in ind_vars:\n",
      "            est_data[varname] = alternative_sample[varname]\n",
      "        est_data = est_data.fillna(0)\n",
      "        data = est_data.as_matrix()\n",
      "#         try:\n",
      "        fit, results = interaction.estimate(data, est_params, SAMPLE_SIZE)\n",
      "        #print fit\n",
      "        #print results\n",
      "        fnames = interaction.add_fnames(ind_vars,est_params)\n",
      "        print misc.resultstotable(fnames,results)\n",
      "        misc.resultstocsv(fit,fnames,results,tmp_outcsv,tblname=tmp_outtitle)\n",
      "        dset.store_coeff(tmp_coeffname,zip(*results)[0],fnames)\n",
      "#         except:\n",
      "#             print 'SINGULAR MATRIX OR OTHER DATA/ESTIMATION PROBLEM'\n",
      "    else:\n",
      "        print 'SAMPLE SIZE TOO SMALL'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimating parameters for segment = 1, size = 1000\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4438.437334\n",
        "Log-liklihood ratio: 0.036206\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |  10.090 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   9.040 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.020 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 | -17.820 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.080 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 2, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4509.807396\n",
        "Log-liklihood ratio: 0.020708\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   4.340 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   3.210 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |      -0.060 |  0.010 |  -9.100 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 | -29.140 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.110 |   0.030 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 3, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4518.194329\n",
        "Log-liklihood ratio: 0.018887\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   2.370 | **           |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  -6.830 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |      -0.150 |  0.010 | -23.560 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |  -4.360 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |      -0.040 |  0.110 |  -0.410 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 4, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4483.018866\n",
        "Log-liklihood ratio: 0.026525\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 |   7.660 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |   1.880 | *            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |  0.010 |   0.030 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 | -10.040 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.080 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "Estimating parameters for segment = 6, size = 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Null Log-liklihood: -4605.170186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Log-liklihood at convergence: -4186.877859\n",
        "Log-liklihood ratio: 0.090831\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|         Variables         | Coefficient | Stderr | T-score | Significance |\n",
        "+===========================+=============+========+=========+==============+\n",
        "|    residential units zone |           0 |      0 | -19.770 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "| non residential sqft zone |           0 |      0 |  28.380 | ***          |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|       allpurpose agglosum |           0 |      0 |  -0.070 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                   acreage |           0 |      0 |   1.510 | .            |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n",
        "|                 in denver |           0 |  0.120 |       0 |              |\n",
        "+---------------------------+-------------+--------+---------+--------------+\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dset.coeffs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Int64Index: 6 entries, 0 to 5\n",
        "Data columns (total 30 columns):\n",
        "(hh_location_1, coeffs)     6  non-null values\n",
        "(hh_location_1, fnames)     6  non-null values\n",
        "(hh_location_2, coeffs)     6  non-null values\n",
        "(hh_location_2, fnames)     6  non-null values\n",
        "(hh_location_3, coeffs)     6  non-null values\n",
        "(hh_location_3, fnames)     6  non-null values\n",
        "(hh_location_4, coeffs)     4  non-null values\n",
        "(hh_location_4, fnames)     4  non-null values\n",
        "(emp_location_1, coeffs)    6  non-null values\n",
        "(emp_location_1, fnames)    6  non-null values\n",
        "(emp_location_2, coeffs)    6  non-null values\n",
        "(emp_location_2, fnames)    6  non-null values\n",
        "(emp_location_3, coeffs)    6  non-null values\n",
        "(emp_location_3, fnames)    6  non-null values\n",
        "(emp_location_4, coeffs)    6  non-null values\n",
        "(emp_location_4, fnames)    6  non-null values\n",
        "(emp_location_5, coeffs)    6  non-null values\n",
        "(emp_location_5, fnames)    6  non-null values\n",
        "(emp_location_6, coeffs)    6  non-null values\n",
        "(emp_location_6, fnames)    6  non-null values\n",
        "(dp_location_1, coeffs)     5  non-null values\n",
        "(dp_location_1, fnames)     5  non-null values\n",
        "(dp_location_2, coeffs)     5  non-null values\n",
        "(dp_location_2, fnames)     5  non-null values\n",
        "(dp_location_3, coeffs)     5  non-null values\n",
        "(dp_location_3, fnames)     5  non-null values\n",
        "(dp_location_4, coeffs)     5  non-null values\n",
        "(dp_location_4, fnames)     5  non-null values\n",
        "(dp_location_6, coeffs)     5  non-null values\n",
        "(dp_location_6, fnames)     5  non-null values\n",
        "dtypes: float64(15), object(15)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 6 entries, 0 to 5\n",
        "Data columns (total 30 columns):\n",
        "(hh_location_1, coeffs)     6  non-null values\n",
        "(hh_location_1, fnames)     6  non-null values\n",
        "(hh_location_2, coeffs)     6  non-null values\n",
        "(hh_location_2, fnames)     6  non-null values\n",
        "(hh_location_3, coeffs)     6  non-null values\n",
        "(hh_location_3, fnames)     6  non-null values\n",
        "(hh_location_4, coeffs)     4  non-null values\n",
        "(hh_location_4, fnames)     4  non-null values\n",
        "(emp_location_1, coeffs)    6  non-null values\n",
        "(emp_location_1, fnames)    6  non-null values\n",
        "(emp_location_2, coeffs)    6  non-null values\n",
        "(emp_location_2, fnames)    6  non-null values\n",
        "(emp_location_3, coeffs)    6  non-null values\n",
        "(emp_location_3, fnames)    6  non-null values\n",
        "(emp_location_4, coeffs)    6  non-null values\n",
        "(emp_location_4, fnames)    6  non-null values\n",
        "(emp_location_5, coeffs)    6  non-null values\n",
        "(emp_location_5, fnames)    6  non-null values\n",
        "(emp_location_6, coeffs)    6  non-null values\n",
        "(emp_location_6, fnames)    6  non-null values\n",
        "(dp_location_1, coeffs)     5  non-null values\n",
        "(dp_location_1, fnames)     5  non-null values\n",
        "(dp_location_2, coeffs)     5  non-null values\n",
        "(dp_location_2, fnames)     5  non-null values\n",
        "(dp_location_3, coeffs)     5  non-null values\n",
        "(dp_location_3, fnames)     5  non-null values\n",
        "(dp_location_4, coeffs)     5  non-null values\n",
        "(dp_location_4, fnames)     5  non-null values\n",
        "(dp_location_6, coeffs)     5  non-null values\n",
        "(dp_location_6, fnames)     5  non-null values\n",
        "dtypes: float64(15), object(15)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Real Estate Price Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# buildings = dset.fetch('buildings')\n",
      "# buildings = buildings[buildings.estim_index==1]\n",
      "# output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic.csv\",\"PARIS HEDONIC MODEL\",\"price_%s\",\"price\"]\n",
      "\n",
      "# ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#              'population_density','tco',]\n",
      "# ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "#              'employment_density','tax_on_professionals','tco',]\n",
      "\n",
      "# segments = buildings.groupby('building_type_id')\n",
      "# for name, segment in segments:\n",
      "#     if name == 1:\n",
      "#         indvars = ind_vars1\n",
      "#     if name == 2:\n",
      "#         indvars = ind_vars2\n",
      "#     if name == 3:\n",
      "#         indvars = ind_vars3\n",
      "#     if name == 4:\n",
      "#         indvars = ind_vars4\n",
      "#     if name == 6:\n",
      "#         indvars = ind_vars6\n",
      "#     est_data = pd.DataFrame(index=segment.index)\n",
      "#     for varname in indvars:\n",
      "#         est_data[varname] = segment[varname]\n",
      "#     est_data = est_data.fillna(0)\n",
      "#     est_data = sm.add_constant(est_data,prepend=False)\n",
      "#     tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "#     print segment\n",
      "#     depvar = segment['price'].apply(np.log)\n",
      "#     print \"Estimating hedonic for %s with %d observations\" % (name,len(segment.index))\n",
      "#     print est_data.describe()\n",
      "\n",
      "#     model = sm.OLS(depvar,est_data)\n",
      "#     results = model.fit()\n",
      "#     print results.summary()\n",
      "\n",
      "#     tmp_outcsv = output_csv%name\n",
      "#     tmp_outtitle = output_title%name\n",
      "#     misc.resultstocsv((results.rsquared,results.rsquared_adj),est_data.columns,\n",
      "#                         zip(results.params,results.bse,results.tvalues),tmp_outcsv,hedonic=1,\n",
      "#                         tblname=output_title)\n",
      "\n",
      "#     dset.store_coeff(tmp_coeffname,results.params.values,results.params.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Coefficients to HDF5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##COEFFICIENTS TO HDF5\n",
      "# coeff_store_path = os.path.join(output_dir,'coeffs.h5')\n",
      "# coeff_store = pd.HDFStore(coeff_store_path)\n",
      "# coeff_store['coeffs'] = dset.coeffs\n",
      "# coeff_store.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dset.coeffs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Index([], dtype=object)</td>\n",
        "      <td>Empty DataFrame</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "Empty DataFrame\n",
        "Columns: []\n",
        "Index: []"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = '_ref_base'\n",
      "for scenario in ['baseline',]: #'low_impact','scen0'\n",
      "    print 'Running scenario: ' + scenario\n",
      "    import time\n",
      "    seconds_start = time.time()\n",
      "    print seconds_start\n",
      "    import numpy as np, pandas as pd, os, statsmodels.api as sm\n",
      "    import synthicity.urbansim.interaction as interaction\n",
      "    from synthicity.utils import misc\n",
      "    import dataset, copy, math\n",
      "    np.random.seed(1)\n",
      "    first_year = 2010\n",
      "    last_year = 2020\n",
      "    summary = {'employment':[],'households':[],'non_residential_sqft':[],'residential_units':[],'price':[]}\n",
      "#     dset = dataset.DRCOGDataset(os.path.join(misc.data_dir(),'drcog.h5'))\n",
      "    \n",
      "    for sim_year in range(first_year,last_year+1):\n",
      "        print 'Simulating year ' + str(sim_year)\n",
      "        \n",
      "    #####Variable calculations\n",
      "#         p = dset.fetch('parcels')\n",
      "#         p['in_denver'] = (p.county_id==8031).astype('int32')\n",
      "#         #building\n",
      "#         b = dset.fetch('buildings')\n",
      "#         b['zone_id'] = p.zone_id[b.parcel_id].values\n",
      "#         b['btype'] = 1*(b.building_type_id==2) + 2*(b.building_type_id==3) + 3*(b.building_type_id==20) + 4*(b.building_type_id==24) + 6*np.invert(np.in1d(b.building_type_id,[2,3,20,24]))\n",
      "#         #household\n",
      "#         hh_estim = dset.fetch('households_for_estimation')\n",
      "#         hh = dset.fetch('households')\n",
      "#         for table in [hh_estim, hh]:\n",
      "#             choosers = table\n",
      "#             choosers['building_type_id'] = b.building_type_id[choosers.building_id].values\n",
      "#             choosers['btype'] = 1*(choosers.building_type_id==2) + 2*(choosers.building_type_id==3) + 3*(choosers.building_type_id==20) + 4*np.invert(np.in1d(choosers.building_type_id,[2,3,20]))\n",
      "#         #establishment\n",
      "#         e = dset.fetch('establishments')\n",
      "#         e['sector_id_six'] = 1*(e.sector_id==61) + 2*(e.sector_id==71) + 3*np.in1d(e.sector_id,[11,21,22,23,31,32,33,42,48,49]) + 4*np.in1d(e.sector_id,[7221,7222,7224]) + 5*np.in1d(e.sector_id,[44,45,7211,7212,7213,7223]) + 6*np.in1d(e.sector_id,[51,52,53,54,55,56,62,81,92])\n",
      "#         #zone\n",
      "#         z = dset.fetch('zones')\n",
      "#         z['residential_units_zone'] = b.groupby('zone_id').residential_units.sum()\n",
      "#         z['non_residential_sqft_zone'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "#         #merge parcels with zones\n",
      "#         pz = pd.merge(p,z,left_on='zone_id',right_index=True)\n",
      "#         #merge buildings with parcels/zones\n",
      "#         dset.d['buildings'] = pd.merge(b,pz,left_on='parcel_id',right_index=True)\n",
      "        \n",
      "        #Record base values for temporal comparison\n",
      "        if sim_year==first_year:\n",
      "            summary['employment'].append(e[e.building_id>0].employees.sum())\n",
      "            summary['households'].append(len(hh[hh.building_id>0].building_id))\n",
      "            summary['non_residential_sqft'].append(b.non_residential_sqft.sum())\n",
      "            summary['residential_units'].append(b.residential_units.sum())\n",
      "\n",
      "#             base_emp = z.groupby('zgpgroup_id').total_employment.sum()\n",
      "#             base_hh = z.groupby('zgpgroup_id').total_households.sum()\n",
      "#             base_ru = z.groupby('zgpgroup_id').total_residential_units.sum()\n",
      "#             base_nr = z.groupby('zgpgroup_id').total_nonresidential_sqft.sum()\n",
      "#             base_pop = z.groupby('zgpgroup_id').total_persons.sum()\n",
      "#             base_emp_zone = z.total_employment.copy()\n",
      "#             base_pop_zone = z.total_persons.copy()\n",
      "        \n",
      "        ##Estimate REPM instead of loading from CSV because it is so fast\n",
      "#         if sim_year==first_year:\n",
      "#             buildings = dset.fetch('buildings')\n",
      "#             buildings = buildings[buildings.estim_index==1]\n",
      "#             output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic-%s.csv\",\"PARIS HEDONIC MODEL (%s)\",\"price_%s\",\"price\"]\n",
      "#             ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "#                          'population_density','tco',]\n",
      "#             ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "#                          'employment_density','tax_on_professionals','tco',]\n",
      "#             segments = buildings.groupby('building_type_id')\n",
      "#             for name, segment in segments:\n",
      "#                 if name == 1:\n",
      "#                     indvars = ind_vars1\n",
      "#                 if name == 2:\n",
      "#                     indvars = ind_vars2\n",
      "#                 if name == 3:\n",
      "#                     indvars = ind_vars3\n",
      "#                 if name == 4:\n",
      "#                     indvars = ind_vars4\n",
      "#                 if name == 6:\n",
      "#                     indvars = ind_vars6\n",
      "#                 est_data = pd.DataFrame(index=segment.index)\n",
      "#                 for varname in indvars:\n",
      "#                     est_data[varname] = segment[varname]\n",
      "#                 est_data = est_data.fillna(0)\n",
      "#                 est_data = sm.add_constant(est_data,prepend=False)\n",
      "#                 tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "#                 #print tmp_coeffname\n",
      "#                 depvar = segment['price'].apply(np.log)\n",
      "#                 print \"Estimating hedonic for %s with %d observations\" % (name,len(segment.index))\n",
      "#                 #print est_data.describe()\n",
      "#                 model = sm.OLS(depvar,est_data)\n",
      "#                 results = model.fit()\n",
      "#                 #print results.summary()\n",
      "#                 tmp_outcsv = output_csv%name\n",
      "#                 tmp_outtitle = output_title%name\n",
      "#                 misc.resultstocsv((results.rsquared,results.rsquared_adj),est_data.columns,\n",
      "#                                     zip(results.params,results.bse,results.tvalues),tmp_outcsv,hedonic=1,\n",
      "#                                     tblname=output_title)\n",
      "#                 dset.store_coeff(tmp_coeffname,results.params.values,results.params.index)\n",
      "                \n",
      "#             ##Load location choice model coefficients from csv or hdf5\n",
      "#             output_dir = os.path.join(os.environ['DATA_HOME'],'output')\n",
      "#             output_dir = os.path.join(output_dir, 'for_runs')\n",
      "#             coeff_store_path = os.path.join(output_dir,'coeffs.h5')\n",
      "#             coeff_store = pd.HDFStore(coeff_store_path)\n",
      "#             dset.coeffs = coeff_store.coeffs.copy()\n",
      "#             coeff_store.close()\n",
      "#             hh_submodels = ['hh_location_1', 'hh_location_2', 'hh_location_3', 'hh_location_4']\n",
      "#             for name in hh_submodels:\n",
      "#                 if name == 'hh_location_3':\n",
      "#                     colname1 = (name,'coeffs')\n",
      "#                     colname2 = (name,'fnames')\n",
      "#                     fnames =  dset.coeffs[colname2].append(pd.Series(['not_paris_subway_stations_x_1car', 'not_paris_subway_stations_x_2pluscar'],index=[48,49]))\n",
      "#                     coeffs =  dset.coeffs[colname1].append(pd.Series([0.0997, 0.0997],index=[48,49]))\n",
      "#                     dset.store_coeff(name,coeffs.values,fnames.values)\n",
      "#                 if name == 'hh_location_1':\n",
      "#                     colname1 = (name,'coeffs')\n",
      "#                     colname2 = (name,'fnames')\n",
      "#                     fnames =  dset.coeffs[colname2].append(pd.Series(['not_paris_subway_stations_x_1car', 'not_paris_subway_stations_x_2pluscar'],index=[48,49]))\n",
      "#                     coeffs =  dset.coeffs[colname1].append(pd.Series([0.0593, 0.0593],index=[48,49]))\n",
      "#                     dset.store_coeff(name,coeffs.values,fnames.values)\n",
      "#                 if name == 'hh_location_2':\n",
      "#                     dset.coeffs[(name,'fnames')][46] = 'not_paris_subway_stations_x_1car'\n",
      "#                     dset.coeffs[(name,'fnames')][47] = 'not_paris_subway_stations_x_2pluscar'\n",
      "#                     dset.coeffs[(name,'coeffs')][46] = 0.0380\n",
      "#                     dset.coeffs[(name,'coeffs')][47] = 0.0380\n",
      "#                 if name == 'hh_location_4':\n",
      "#                     dset.coeffs[(name,'fnames')][47] = 'not_paris_subway_stations_x_1car'\n",
      "#                     dset.coeffs[(name,'coeffs')][47] = 0.0277\n",
      "#                     dset.coeffs[(name,'fnames')][48] = 'not_paris_subway_stations_x_2pluscar'\n",
      "#                     dset.coeffs[(name,'coeffs')][48] = 0.0277\n",
      "                    \n",
      "#     ############     SCHEDULED DEVELOPMENT EVENTS\n",
      "#         if scenario == 'baseline':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_baseline')\n",
      "#         if scenario == 'low_impact':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_low_impact')\n",
      "#         if scenario == 'scen0':\n",
      "#             sched_events = dset.fetch('scheduled_development_events_scen0')\n",
      "#         scheduled_nonres_sqft = sched_events[(sched_events.amount>0)*(sched_events.year==sim_year)*(sched_events.attribute=='non_residential_sqft')]\n",
      "#         print 'Added %s scheduled non-residential projects.' % len(scheduled_nonres_sqft.index)\n",
      "#         if len(scheduled_nonres_sqft.index)>0:\n",
      "#             scheduled_nonres_sqft = scheduled_nonres_sqft.reset_index().groupby('building_id').amount.sum()\n",
      "#             dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,scheduled_nonres_sqft.index)] = dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,scheduled_nonres_sqft.index)] + scheduled_nonres_sqft\n",
      "#         scheduled_resunits = sched_events[(sched_events.amount>0)*(sched_events.year==sim_year)*(sched_events.attribute=='residential_units')]\n",
      "#         print 'Added %s scheduled residential projects.' % len(scheduled_resunits.index)\n",
      "#         if len(scheduled_resunits.index)>0:\n",
      "#             scheduled_resunits = scheduled_resunits.reset_index().groupby('building_id').amount.sum()\n",
      "#             dset.buildings.residential_units[np.in1d(dset.buildings.index,scheduled_resunits.index)] = dset.buildings.residential_units[np.in1d(dset.buildings.index,scheduled_resunits.index)] + scheduled_resunits\n",
      "\n",
      "\n",
      "    ############     ELCM\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"drcog-coeff-elcm-%s.csv\",\"DRCOG EMPLOYMENT LOCATION CHOICE MODELS (%s)\",\"emp_location_%s\",\"establishment_building_ids\")\n",
      "        dset.establishments['home_based_status']=0\n",
      "        if scenario == 'baseline':\n",
      "            new_jobs = {\"table\": \"dset.establishments\",\"writetotmp\": \"establishments\",\"model\": \"transitionmodel\",\"first_year\": 2010,\"control_totals\": \"dset.annual_employment_control_totals\",\n",
      "                        \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_jobs\",\"size_field\":\"employees\"}\n",
      "        import synthicity.urbansim.transitionmodel as transitionmodel\n",
      "        transitionmodel.simulate(dset,new_jobs,year=sim_year,show=True)\n",
      "        year = sim_year\n",
      "        choosers = dset.fetch('establishments')\n",
      "        depvar = 'building_id'\n",
      "    #     rate_table = dset.annual_job_relocation_rates\n",
      "    #     rate_table = rate_table*.1\n",
      "    #     rate_field = \"job_relocation_probability\"\n",
      "    #     movers = dset.relocation_rates(choosers,rate_table,rate_field)\n",
      "    #     choosers[depvar].ix[movers] = -1\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.non_residential_sqft>0)]\n",
      "        alternatives['job_spaces'] = alternatives.non_residential_sqft/alternatives.building_sqft_per_job\n",
      "        empty_units = alternatives.job_spaces.sub(choosers.groupby('building_id').employees.sum(),fill_value=0).astype('int')\n",
      "        alts = alternatives.ix[empty_units.index]\n",
      "        alts[\"supply\"] = empty_units\n",
      "        lotterychoices = True\n",
      "        pdf = pd.DataFrame(index=alts.index)\n",
      "        segments = movers.groupby(['sector_id_six',])\n",
      "        \n",
      "        ind_vars1=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        ind_vars2=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        ind_vars3=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        ind_vars4=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        ind_vars5=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        ind_vars6=['residential_units_zone','non_residential_sqft_zone','allpurpose_agglosum','acreage','unit_price_non_residential','in_denver',]\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            if name == 1:\n",
      "                ind_vars = ind_vars1 \n",
      "            if name == 2:\n",
      "                ind_vars = ind_vars2\n",
      "            if name == 3:\n",
      "                ind_vars = ind_vars3\n",
      "            if name == 4:\n",
      "                ind_vars = ind_vars4\n",
      "            if name == 5:\n",
      "                ind_vars = ind_vars5\n",
      "            if name == 6:\n",
      "                ind_vars = ind_vars6\n",
      "             \n",
      "            segment = segment.head(1)\n",
      "            name_coeff= str(name)\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name_coeff\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "#             alternative_sample['ln_nonres_price_x_more_than_10_employees'] = (alternative_sample.ln_average_nonres_price6*alternative_sample.more_than_10_employees)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            pdf['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "                \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        mask = np.zeros(len(alts.index),dtype='bool')\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            name = str(name)\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "            p=pdf['segment%s'%name].values\n",
      "            #p=pdf['segment%s'%name].values\n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                p[alternatives.supply<minsize] = 0\n",
      "                #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "                alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "                return mask,new_homes\n",
      "            tmp = segment['employees']\n",
      "            #tmp /= 100.0 ##If scaling demand amount is desired\n",
      "            for name, subsegment in reversed(list(segment.groupby(tmp.astype('int')))):\n",
      "                #print \"Running subsegment with size = %s, num agents = %d\" % (name, len(subsegment.index))\n",
      "                mask,new_homes = choose(p,mask,alts,subsegment,new_homes,minsize=int(name))\n",
      "        \n",
      "        build_cnts = new_homes.value_counts()  #num estabs place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = dset.establishments # need to go back to the whole dataset\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        \n",
      "        \n",
      "    #################     HLCM\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"paris-coeff-hlcm-%s.csv\",\"PARIS HOUSEHOLD LOCATION CHOICE MODELS (%s)\",\"hh_location_%s\",\"household_building_ids\")\n",
      "        if scenario == 'baseline':\n",
      "            new_hhlds = {\"table\": \"dset.households\",\"writetotmp\": \"households\",\"model\": \"transitionmodel\",\"first_year\": 1999,\"control_totals\": \"dset.annual_household_control_totals_baseline\",\n",
      "                         \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_households\"}\n",
      "        if scenario == 'low_impact':\n",
      "            new_hhlds = {\"table\": \"dset.households\",\"writetotmp\": \"households\",\"model\": \"transitionmodel\",\"first_year\": 1999,\"control_totals\": \"dset.annual_household_control_totals_low_impact\",\n",
      "                         \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_households\"}\n",
      "        if scenario == 'scen0':\n",
      "            new_hhlds = {\"table\": \"dset.households\",\"writetotmp\": \"households\",\"model\": \"transitionmodel\",\"first_year\": 1999,\"control_totals\": \"dset.annual_household_control_totals_scen0\",\n",
      "                         \"geography_field\": \"building_id\",\"amount_field\": \"total_number_of_households\"}\n",
      "        import synthicity.urbansim.transitionmodel as transitionmodel\n",
      "        transitionmodel.simulate(dset,new_hhlds,year=sim_year,show=True,subtract=True)\n",
      "        year = sim_year\n",
      "        choosers = dset.fetch('households')\n",
      "        depvar = 'building_id'\n",
      "        rate_table = dset.annual_household_relocation_rates\n",
      "        rate_table = rate_table*.1\n",
      "        rate_field = \"probability_of_relocating\"\n",
      "        movers = dset.relocation_rates(choosers,rate_table,rate_field)\n",
      "        choosers[depvar].ix[movers] = -1\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.residential_units>0)]\n",
      "        empty_units = dset.buildings[(dset.buildings.residential_units>0)].residential_units.sub(choosers.groupby('building_id').size(),fill_value=0)\n",
      "        empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "        alternatives = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "        alts1 = alternatives[alternatives.building_type_id==1]\n",
      "        alts2 = alternatives[alternatives.building_type_id==2]\n",
      "        alts3 = alternatives[alternatives.building_type_id==3]\n",
      "        alts4 = alternatives[alternatives.building_type_id==4]\n",
      "        pdf1 = pd.DataFrame(index=alts1.index)\n",
      "        pdf2 = pd.DataFrame(index=alts2.index) \n",
      "        pdf3 = pd.DataFrame(index=alts3.index)\n",
      "        pdf4 = pd.DataFrame(index=alts4.index)\n",
      "        \n",
      "        #segments = movers.groupby(['btype_tenure',])\n",
      "        #choosers.groupby(['btype_tenure','income_cat','age_cat','sex_of_head'])\n",
      "        segments = movers.groupby(['btype_tenure','low_inc','old','race_id','with_child','with_car']) \n",
      "        \n",
      "        ind_vars1=[\"ln_residential_units_owner_house\",'in_paris','in_paris_suburbs','cd_chatelet','rail_stations_x_0car','rail_stations_x_1car','rail_stations_x_2pluscar',\n",
      "                   'subway_stations_x_0car','subway_stations_x_1car','subway_stations_x_2pluscar','cnoise','cpbois','cpparc_jardin','cpeau','perc_gardens_x_children',\n",
      "                   'ln_price1_x_low_income','ln_price1_x_mid_income','ln_price1_x_high_income','percent_middle_age_x_high_inc','perc_foreign_x_french','perc_foreign_x_foreign','low_inc_x_percent_low_inc','mid_inc_x_percent_mid_inc',\n",
      "                   'high_inc_x_percent_high_inc','hhsize2_x_percent_hhsize2','hhsize3plus_x_percent_hhsize3plus','perc_young_x_young','perc_middle_age_x_middle_age','perc_old_x_old',\n",
      "                   'perc_with_child_x_child_in_hh','tco_x_0car','tco_x_1car','tco_x_2pluscar','vpo_x_0car','vpo_x_1car','vpo_x_2pluscar',\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99',\n",
      "                   'not_paris_subway_stations_x_2pluscar','not_paris_subway_stations_x_1car']\n",
      "        ind_vars2=[\"ln_residential_units_owner_flat\",'in_paris','in_paris_suburbs','cd_chatelet','rail_stations_x_0car','rail_stations_x_1car','rail_stations_x_2pluscar',\n",
      "                   'subway_stations_x_0car','subway_stations_x_1car','subway_stations_x_2pluscar','cnoise','cpbois','cpparc_jardin','cpeau','perc_gardens_x_children',\n",
      "                   'ln_price2_x_low_income','ln_price2_x_mid_income','perc_foreign_x_french','perc_foreign_x_foreign','low_inc_x_percent_low_inc','mid_inc_x_percent_mid_inc',\n",
      "                   'high_inc_x_percent_high_inc','hhsize2_x_percent_hhsize2','hhsize3plus_x_percent_hhsize3plus','perc_young_x_young','perc_middle_age_x_middle_age','perc_old_x_old',\n",
      "                   'perc_with_child_x_child_in_hh','tco_x_0car','tco_x_1car','tco_x_2pluscar','vpo_x_0car','vpo_x_1car','vpo_x_2pluscar',\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99',\n",
      "                   'not_paris_subway_stations_x_2pluscar','not_paris_subway_stations_x_1car']\n",
      "        ind_vars3=[\"ln_residential_units_renter_house\",'in_paris','in_paris_suburbs','cd_chatelet','rail_stations_x_0car','rail_stations_x_1car','rail_stations_x_2pluscar',\n",
      "                   'subway_stations_x_0car','subway_stations_x_1car','subway_stations_x_2pluscar','cnoise','cpbois','cpparc_jardin','cpeau','perc_gardens_x_children',\n",
      "                   'ln_price3_x_low_income','ln_price3_x_mid_income','ln_price3_x_high_income','perc_foreign_x_french','perc_foreign_x_foreign','low_inc_x_percent_low_inc','mid_inc_x_percent_mid_inc',\n",
      "                   'high_inc_x_percent_high_inc','hhsize2_x_percent_hhsize2','hhsize3plus_x_percent_hhsize3plus','perc_young_x_young','perc_middle_age_x_middle_age','perc_old_x_old',\n",
      "                   'perc_with_child_x_child_in_hh','percent_old_x_low_inc','tco_x_0car','tco_x_1car','tco_x_2pluscar','vpo_x_0car','vpo_x_1car','vpo_x_2pluscar',\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99',\n",
      "                   'not_paris_subway_stations_x_2pluscar','not_paris_subway_stations_x_1car']\n",
      "        ind_vars4=[\"ln_residential_units_renter_flat\",'in_paris','in_paris_suburbs','cd_chatelet','rail_stations_x_0car','rail_stations_x_1car','rail_stations_x_2pluscar',\n",
      "                   'subway_stations_x_0car','subway_stations_x_1car','subway_stations_x_2pluscar','cnoise','cpbois','cpparc_jardin','cpeau','perc_gardens_x_children',\n",
      "                   'ln_price4_x_low_income','ln_price4_x_mid_income','perc_foreign_x_french','perc_foreign_x_foreign','low_inc_x_percent_low_inc','mid_inc_x_percent_mid_inc',\n",
      "                   'high_inc_x_percent_high_inc','hhsize2_x_percent_hhsize2','hhsize3plus_x_percent_hhsize3plus','perc_young_x_young','perc_middle_age_x_middle_age','perc_old_x_old',\n",
      "                   'perc_with_child_x_child_in_hh','percent_middle_age_x_mid_inc','tco_x_0car','tco_x_1car','tco_x_2pluscar','vpo_x_0car','vpo_x_1car','vpo_x_2pluscar',\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99',\n",
      "                   'not_paris_subway_stations_x_2pluscar','not_paris_subway_stations_x_1car'] \n",
      "    \n",
      "        for name, segment in segments:\n",
      "            if type(name) is np.int64:  name = (name,0)\n",
      "            if name[0] == 1:\n",
      "                alts = alts1\n",
      "                ind_vars = ind_vars1\n",
      "            if name[0] == 2:\n",
      "                alts = alts2\n",
      "                ind_vars = ind_vars2\n",
      "            if name[0] == 3:\n",
      "                alts = alts3\n",
      "                ind_vars = ind_vars3\n",
      "            if name[0] == 4:\n",
      "                alts = alts4\n",
      "                ind_vars = ind_vars4\n",
      "            segment = segment.head(1)\n",
      "            name_coeff = str(name[0])\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name_coeff\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "            alternative_sample['high_inc_x_percent_high_inc'] = (alternative_sample.high_inc*alternative_sample.percent_high_income)\n",
      "            alternative_sample['mid_inc_x_percent_mid_inc'] = (alternative_sample.mid_inc*alternative_sample.percent_mid_income)\n",
      "            alternative_sample['low_inc_x_percent_low_inc'] = (alternative_sample.low_inc*alternative_sample.percent_low_income)\n",
      "            alternative_sample['hhsize3plus_x_percent_hhsize3plus'] = (alternative_sample.hhsize3plus*alternative_sample.percent_hhsize3plus)\n",
      "            alternative_sample['hhsize2_x_percent_hhsize2'] = (alternative_sample.hhsize2*alternative_sample.percent_hhsize2)\n",
      "            #alternative_sample['same_dpt_as_previous'] = (alternative_sample.previous_dpt==alternative_sample.dept_id).astype('int32')\n",
      "            alternative_sample['rail_stations_x_0car'] = (alternative_sample.ctrain9*(alternative_sample.cars==0)).astype('int32')\n",
      "            alternative_sample['rail_stations_x_1car'] = (alternative_sample.ctrain9*(alternative_sample.cars==1)).astype('int32')\n",
      "            alternative_sample['rail_stations_x_2pluscar'] = (alternative_sample.ctrain9*(alternative_sample.cars>1)).astype('int32')\n",
      "            alternative_sample['subway_stations_x_0car'] = (alternative_sample.csubway9*(alternative_sample.cars==0)).astype('int32')\n",
      "            alternative_sample['subway_stations_x_1car'] = (alternative_sample.csubway9*(alternative_sample.zgpgroup75==1)*(alternative_sample.cars==1)).astype('int32')\n",
      "            alternative_sample['subway_stations_x_2pluscar'] = (alternative_sample.csubway9*(alternative_sample.zgpgroup75==1)*(alternative_sample.cars>1)).astype('int32')\n",
      "            alternative_sample['tco_x_0car'] = (alternative_sample.tco*(alternative_sample.cars==0)).astype('int32')\n",
      "            alternative_sample['tco_x_1car'] = (alternative_sample.tco*(alternative_sample.cars==1)).astype('int32')\n",
      "            alternative_sample['tco_x_2pluscar'] = (alternative_sample.tco*(alternative_sample.cars>1)).astype('int32')\n",
      "            alternative_sample['vpo_x_0car'] = (alternative_sample.vpo*(alternative_sample.cars==0)).astype('int32')\n",
      "            alternative_sample['vpo_x_1car'] = (alternative_sample.vpo*(alternative_sample.cars==1)).astype('int32')\n",
      "            alternative_sample['vpo_x_2pluscar'] = (alternative_sample.vpo*(alternative_sample.cars>1)).astype('int32')\n",
      "            alternative_sample['perc_gardens_x_children'] = (alternative_sample.cpparc_jardin*alternative_sample.children).astype('int32')\n",
      "            alternative_sample['perc_foreign_x_french'] = (alternative_sample.percent_foreigners*(alternative_sample.race_id==0))\n",
      "            alternative_sample['perc_foreign_x_foreign'] = (alternative_sample.percent_foreigners*(alternative_sample.race_id==1))\n",
      "            alternative_sample['perc_young_x_young'] = (alternative_sample.percent_young*alternative_sample.young)\n",
      "            alternative_sample['perc_middle_age_x_middle_age'] = (alternative_sample.percent_middle_age*alternative_sample.middle_age)\n",
      "            alternative_sample['perc_old_x_old'] = (alternative_sample.percent_old*alternative_sample.old)\n",
      "            alternative_sample['perc_with_child_x_child_in_hh'] = (alternative_sample.with_child*alternative_sample.percent_with_child)\n",
      "            alternative_sample['percent_middle_age_x_high_inc'] = (alternative_sample.high_inc*alternative_sample.percent_middle_age)\n",
      "            alternative_sample['percent_old_x_low_inc'] = (alternative_sample.low_inc*alternative_sample.percent_old)\n",
      "            alternative_sample['percent_middle_age_x_mid_inc'] = (alternative_sample.mid_inc*alternative_sample.percent_middle_age)\n",
      "            alternative_sample['not_paris_subway_stations_x_1car'] = (alternative_sample.csubway9*(alternative_sample.zgpgroup75<>1)*(alternative_sample.cars==1)).astype('int32')\n",
      "            alternative_sample['not_paris_subway_stations_x_2pluscar'] = (alternative_sample.csubway9*(alternative_sample.zgpgroup75<>1)*(alternative_sample.cars>1)).astype('int32')\n",
      "            if int(name_coeff)==1:\n",
      "                alternative_sample['ln_price1_x_low_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.low_inc)\n",
      "                alternative_sample['ln_price1_x_mid_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.mid_inc)\n",
      "                alternative_sample['ln_price1_x_high_income'] = (alternative_sample.ln_average_res_price1*alternative_sample.high_inc)\n",
      "            if int(name_coeff)==2:\n",
      "                alternative_sample['ln_price2_x_low_income'] = (alternative_sample.ln_average_res_price2*alternative_sample.low_inc)\n",
      "                alternative_sample['ln_price2_x_mid_income'] = (alternative_sample.ln_average_res_price2*alternative_sample.mid_inc)\n",
      "                alternative_sample['ln_price2_x_high_income'] = (alternative_sample.ln_average_res_price2*alternative_sample.high_inc)\n",
      "            if int(name_coeff)==3:\n",
      "                alternative_sample['ln_price3_x_low_income'] = (alternative_sample.ln_average_res_price3*alternative_sample.low_inc)\n",
      "                alternative_sample['ln_price3_x_mid_income'] = (alternative_sample.ln_average_res_price3*alternative_sample.mid_inc)\n",
      "                alternative_sample['ln_price3_x_high_income'] = (alternative_sample.ln_average_res_price3*alternative_sample.high_inc)\n",
      "            if int(name_coeff)==4:\n",
      "                alternative_sample['ln_price4_x_low_income'] = (alternative_sample.ln_average_res_price4*alternative_sample.low_inc)\n",
      "                alternative_sample['ln_price4_x_mid_income'] = (alternative_sample.ln_average_res_price4*alternative_sample.mid_inc)\n",
      "                alternative_sample['ln_price4_x_high_income'] = (alternative_sample.ln_average_res_price4*alternative_sample.high_inc)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            if int(name_coeff) == 1:\n",
      "                pdf1['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index)  \n",
      "            if int(name_coeff) == 2:\n",
      "                pdf2['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name_coeff) == 3:\n",
      "                pdf3['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name_coeff) == 4:\n",
      "                pdf4['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "     \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        #mask = np.zeros(len(alternatives.index),dtype='bool')\n",
      "        for name, segment in segments:\n",
      "            if type(name) is np.int64:  name = (name,0)\n",
      "            name_coeff = str(name[0])\n",
      "            name = str(name)\n",
      "            if int(name_coeff) == 1:\n",
      "                p=pdf1['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts1.index),dtype='bool')\n",
      "            if int(name_coeff) == 2:\n",
      "                p=pdf2['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts2.index),dtype='bool')\n",
      "            if int(name_coeff) == 3:\n",
      "                p=pdf3['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts3.index),dtype='bool')\n",
      "            if int(name_coeff) == 4:\n",
      "                p=pdf4['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts4.index),dtype='bool')\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "            #p=pdf['segment%s'%name].values\n",
      "         \n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                p[mask] = 0 # already chosen\n",
      "                #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "                mask[indexes] = 1\n",
      "              \n",
      "                return mask,new_homes\n",
      "            if int(name_coeff) == 1:\n",
      "                mask,new_homes = choose(p,mask,alts1,segment,new_homes)\n",
      "            if int(name_coeff) == 2:\n",
      "                mask,new_homes = choose(p,mask,alts2,segment,new_homes)\n",
      "            if int(name_coeff) == 3:\n",
      "                mask,new_homes = choose(p,mask,alts3,segment,new_homes)\n",
      "            if int(name_coeff) == 4:\n",
      "                mask,new_homes = choose(p,mask,alts4,segment,new_homes)\n",
      "            \n",
      "        build_cnts = new_homes.value_counts()  #num households place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = dset.households # need to go back to the whole dataset\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        \n",
      "        \n",
      "    #################     RDPLCM\n",
      "        target_vacancy1 = .081\n",
      "        target_vacancy2 = .081\n",
      "        target_vacancy3 = .081\n",
      "        target_vacancy4 = .081\n",
      "        target_vacancy6 = .097\n",
      "        target_vacancies = pd.Series([target_vacancy1,target_vacancy2,target_vacancy3,target_vacancy4,target_vacancy6],index=[1,2,3,4,6])\n",
      "        households_by_btype = dset.households.groupby('btype_tenure').building_id.count()\n",
      "        resunits_by_btype = dset.buildings[dset.buildings.building_type_id<5].groupby('building_type_id').residential_units.sum()\n",
      "        vacant_resunits = resunits_by_btype - households_by_btype\n",
      "        vacant_resunits = vacant_resunits[vacant_resunits.index.values<6]\n",
      "        target_vacant_resunits = resunits_by_btype * target_vacancies\n",
      "        diff_resunits = np.round(target_vacant_resunits - vacant_resunits)\n",
      "        print 'Residential units by building type to construct:  '\n",
      "        building_type_ids = []\n",
      "        building_ids = []\n",
      "        for idx_btype in diff_resunits[diff_resunits>0].index:\n",
      "            building_type_id = idx_btype\n",
      "            residential_units_to_build = int(diff_resunits[idx_btype])\n",
      "            print building_type_id, residential_units_to_build\n",
      "            building_type_ids += [building_type_id]*residential_units_to_build\n",
      "            building_ids += [-1]*residential_units_to_build\n",
      "        building_type_ids = np.array(building_type_ids)\n",
      "        building_ids = np.array(building_ids)\n",
      "        residential_unit_ids = np.arange(len(building_ids))+1\n",
      "        residential_units = pd.DataFrame({'building_type_id':building_type_ids,'building_id':building_ids,'residential_unit_id':residential_unit_ids})\n",
      "        residential_units = residential_units.set_index('residential_unit_id')\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"paris-coeff-dplcm-%s.csv\",\"PARIS DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "        year = sim_year\n",
      "        choosers = residential_units\n",
      "        depvar = 'building_id'\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.residential_units_capacity>0)]\n",
      "        alternatives.residential_units_capacity[alternatives.zgpgroup75==1] = np.round(alternatives.residential_units_capacity[alternatives.zgpgroup75==1]*.6)\n",
      "        empty_units = dset.buildings[(dset.buildings.residential_units_capacity>0)].residential_units_capacity.sub(dset.buildings.residential_units,fill_value=0)\n",
      "        empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "        empty_units[empty_units>2000] = 2000\n",
      "        ind_vars1=['in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpbois','cpequipem_sante','cpparc_jardin','cpsport','cpeau','cpraft90','percent_hh_one_worker',\n",
      "                   'percent_hh_twoplus_workers','cprbef15','percent_foreigners','percent_young','percent_old','percent_hhsize2', 'percent_hhsize3plus',\n",
      "                   'employment_density','population_density','vpo',] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        ind_vars2=['in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpbois','cpequipem_sante','cpparc_jardin','cpsport','cpeau','cpraft90','percent_hh_one_worker',\n",
      "                   'percent_hh_twoplus_workers','cprbef15','percent_foreigners','percent_young','percent_old','percent_hhsize2', 'percent_hhsize3plus',\n",
      "                   'employment_density','population_density','vpo',] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        ind_vars3=['in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpbois','cpequipem_sante','cpparc_jardin','cpsport','cpeau','cpraft90','percent_hh_one_worker',\n",
      "                   'percent_hh_twoplus_workers','cprbef15','percent_foreigners','percent_young','percent_old','percent_hhsize2', 'percent_hhsize3plus',\n",
      "                   'employment_density','population_density','vpo',] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        ind_vars4=['in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpbois','cpequipem_sante','cpparc_jardin','cpsport','cpeau','cpraft90','percent_hh_one_worker',\n",
      "                   'percent_hh_threeplus_workers','cprbef15','percent_foreigners','percent_young','percent_old','percent_hhsize2', 'percent_hhsize3plus',\n",
      "                   'employment_density','population_density','vpo',] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        indvars_together = ind_vars1 + ind_vars2 + ind_vars3 + ind_vars4 + ['building_type_id','zone_id','zgp_id','dept_id','residential_units','residential_units_capacity','non_residential_sqft','non_residential_sqft_capacity']\n",
      "        columns_to_keep = np.unique(indvars_together)\n",
      "        alternatives = alternatives[list(columns_to_keep)]\n",
      "        alternatives = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "        alts1 = alternatives[alternatives.building_type_id==1]\n",
      "        alts2 = alternatives[alternatives.building_type_id==2]\n",
      "        alts3 = alternatives[alternatives.building_type_id==3]\n",
      "        alts4 = alternatives[alternatives.building_type_id==4]\n",
      "        \n",
      "        segments = movers.groupby(['building_type_id',])\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            if name == 1:\n",
      "                alts = alts1\n",
      "                ind_vars = ind_vars1\n",
      "                pdf1 = pd.DataFrame(index=alts1.index) \n",
      "            if name == 2:\n",
      "                alts = alts2\n",
      "                ind_vars = ind_vars2\n",
      "                pdf2 = pd.DataFrame(index=alts2.index) \n",
      "            if name == 3:\n",
      "                alts = alts3\n",
      "                ind_vars = ind_vars3\n",
      "                pdf3 = pd.DataFrame(index=alts3.index) \n",
      "            if name == 4:\n",
      "                alts = alts4\n",
      "                ind_vars = ind_vars4\n",
      "                pdf4 = pd.DataFrame(index=alts4.index) \n",
      "            \n",
      "            segment = segment.head(1)\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            if int(name) == 1:\n",
      "                pdf1['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index)  \n",
      "            if int(name) == 2:\n",
      "                pdf2['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name) == 3:\n",
      "                pdf3['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "            if int(name) == 4:\n",
      "                pdf4['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "     \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        #mask = np.zeros(len(alternatives.index),dtype='bool')\n",
      "        for name, segment in segments:\n",
      "            name = str(name)\n",
      "            if int(name) == 1:\n",
      "                p=pdf1['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts1.index),dtype='bool')\n",
      "            if int(name) == 2:\n",
      "                p=pdf2['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts2.index),dtype='bool')\n",
      "            if int(name) == 3:\n",
      "                p=pdf3['segment%s'%name].values \n",
      "                mask = np.zeros(len(alts3.index),dtype='bool')\n",
      "            if int(name) == 4:\n",
      "                p=pdf4['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts4.index),dtype='bool')\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "            #p=pdf['segment%s'%name].values\n",
      "         \n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                if minsize is not None: p[alternatives.supply<minsize] = 0\n",
      "                else: p[mask] = 0 # already chosen\n",
      "    #             print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "            \n",
      "                if minsize is not None: alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "                else: mask[indexes] = 1\n",
      "              \n",
      "                return mask,new_homes\n",
      "            if int(name) == 1:\n",
      "                mask,new_homes = choose(p,mask,alts1,segment,new_homes)\n",
      "            if int(name) == 2:\n",
      "                mask,new_homes = choose(p,mask,alts2,segment,new_homes)\n",
      "            if int(name) == 3:\n",
      "                mask,new_homes = choose(p,mask,alts3,segment,new_homes)\n",
      "            if int(name) == 4:\n",
      "                mask,new_homes = choose(p,mask,alts4,segment,new_homes)\n",
      "            \n",
      "        build_cnts = new_homes.value_counts()  #num resunits place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = residential_units # need to go back to the whole dataset *****************\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr(output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        new_res_construction_totals = residential_units.groupby('building_id').size()\n",
      "        print 'Previous residential unit total:'\n",
      "        print dset.buildings.residential_units.sum()\n",
      "        dset.buildings.residential_units[np.in1d(dset.buildings.index,new_res_construction_totals.index)] = dset.buildings.residential_units[np.in1d(dset.buildings.index,new_res_construction_totals.index)] + new_res_construction_totals\n",
      "        print 'Current residential unit total:'\n",
      "        print dset.buildings.residential_units.sum()\n",
      "        \n",
      "        \n",
      "    #################     NRDPLCM\n",
      "        target_vacancy6 = .147\n",
      "        employment_by_building = dset.establishments.groupby('building_id').employees.sum()\n",
      "        bsqft_job = dset.buildings[dset.buildings.building_type_id==6].building_sqft_per_job\n",
      "        occupied_nonres_sqft = employment_by_building*bsqft_job\n",
      "        total_occupied_nonres_sqft = occupied_nonres_sqft.sum()\n",
      "        total_nonres_sqft = dset.buildings.non_residential_sqft.sum()\n",
      "        vacant_nonres_sqft = total_nonres_sqft - total_occupied_nonres_sqft\n",
      "        target_vacant_nonres_sqft = total_nonres_sqft*target_vacancy6\n",
      "        nonres_sqft_to_build = target_vacant_nonres_sqft - vacant_nonres_sqft\n",
      "        print 'Non-residential sqft to construct:  '\n",
      "        print nonres_sqft_to_build\n",
      "        nonres_units_to_build = int(round(nonres_sqft_to_build/500.0))\n",
      "        print 'Non-residential units to construct:  '\n",
      "        print nonres_units_to_build\n",
      "        building_type_ids = [6]*nonres_units_to_build\n",
      "        nonres_building_ids = [-1]*nonres_units_to_build\n",
      "        building_type_ids = np.array(building_type_ids)\n",
      "        nonres_building_ids = np.array(nonres_building_ids)\n",
      "        nonres_unit_ids = np.arange(len(nonres_building_ids))+1\n",
      "        nonres_units = pd.DataFrame({'building_type_id':building_type_ids,'building_id':nonres_building_ids,'nonres_unit_id':nonres_unit_ids})\n",
      "        nonres_units = nonres_units.set_index('nonres_unit_id')\n",
      "        output_csv, output_title, coeff_name, output_varname = (\"paris-coeff-dplcm-%s.csv\",\"PARIS DEVPROJECT LOCATION CHOICE MODELS (%s)\",\"dp_location_%s\",\"devproject_building_ids\")\n",
      "        year = sim_year\n",
      "        choosers = nonres_units\n",
      "        depvar = 'building_id'\n",
      "        movers = choosers[choosers[depvar]==-1]\n",
      "        print \"Total new agents and movers = %d\" % len(movers.index)\n",
      "        alternatives = dset.buildings[(dset.buildings.non_residential_sqft_capacity>0)*(dset.buildings.zgpgroup75!=1)]\n",
      "        alternatives['nonres_units'] = alternatives.non_residential_sqft/500\n",
      "        alternatives['nonres_units_capacity'] = alternatives.non_residential_sqft_capacity/500\n",
      "        empty_units = alternatives.nonres_units_capacity.sub(alternatives.nonres_units,fill_value=0)\n",
      "        empty_units = empty_units[empty_units>0].order(ascending=False)\n",
      "        empty_units[empty_units>2500] = 2500\n",
      "        ind_vars6=['in_la_defense','in_new_town','in_paris','in_paris_suburbs','distance_to_arterial','distance_to_highway','cd_chatelet','ln_land_area','csubway9','ctrain9',\n",
      "                   'percent_high_income','percent_low_income','cnoise','cpraft90','percent_hh_one_worker','percent_hh_twoplus_workers','cprbef15','percent_foreigners','percent_young','percent_old',\n",
      "                   'percent_hhsize2', 'percent_hhsize3plus','employment_density','population_density','vpo'\n",
      "                   ] + ['zgpgroup21','zgpgroup22','zgpgroup23','zgpgroup24','zgpgroup25','zgpgroup26','zgpgroup47','zgpgroup48','zgpgroup49','zgpgroup50','zgpgroup75','zgpgroup99']\n",
      "        indvars_together = ind_vars6 + ['building_type_id','zone_id','zgp_id','dept_id','residential_units','residential_units_capacity','non_residential_sqft','non_residential_sqft_capacity']\n",
      "        columns_to_keep = np.unique(indvars_together)\n",
      "        alternatives = alternatives[list(columns_to_keep)]\n",
      "        alts6 = alternatives.ix[np.repeat(empty_units.index,empty_units.values.astype('int'))]\n",
      "        \n",
      "        segments = movers.groupby(['building_type_id',])\n",
      "        \n",
      "        for name, segment in segments:\n",
      "            if name == 6:\n",
      "                alts = alts6\n",
      "                ind_vars = ind_vars6\n",
      "                pdf6 = pd.DataFrame(index=alts.index) \n",
      "            \n",
      "            segment = segment.head(1)\n",
      "            name = str(name)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            SAMPLE_SIZE = alts.index.size \n",
      "            numchoosers = segment.shape[0]\n",
      "            numalts = alts.shape[0]\n",
      "            sample = np.tile(alts.index.values,numchoosers)\n",
      "            alts_sample = alts #sample#alternatives\n",
      "            alts_sample['join_index'] = np.repeat(segment.index,SAMPLE_SIZE)\n",
      "            alts_sample = pd.merge(alts_sample,segment,left_on='join_index',right_index=True,suffixes=('','_r'))\n",
      "            chosen = np.zeros((numchoosers,SAMPLE_SIZE))\n",
      "            chosen[:,0] = 1\n",
      "            sample, alternative_sample, est_params = sample, alts_sample, ('mnl',chosen)\n",
      "            est_data = pd.DataFrame(index=alternative_sample.index)\n",
      "            for varname in ind_vars:\n",
      "                est_data[varname] = alternative_sample[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            data = est_data\n",
      "            data = data.as_matrix()\n",
      "            coeff = dset.load_coeff(tmp_coeffname)\n",
      "            probs = interaction.mnl_simulate(data,coeff,numalts=SAMPLE_SIZE,returnprobs=1)\n",
      "            if int(name) == 6:\n",
      "                pdf6['segment%s'%name] = pd.Series(probs.flatten(),index=alts.index) \n",
      "        new_homes = pd.Series(np.ones(len(movers.index))*-1,index=movers.index)\n",
      "        for name, segment in segments:\n",
      "            name = str(name)\n",
      "            if int(name) == 6:\n",
      "                p=pdf6['segment%s'%name].values\n",
      "                mask = np.zeros(len(alts6.index),dtype='bool')\n",
      "            print \"Assigning units to %d agents of segment %s\" % (len(segment.index),name)\n",
      "         \n",
      "            def choose(p,mask,alternatives,segment,new_homes,minsize=None):\n",
      "                p = copy.copy(p)\n",
      "                if minsize is not None: p[alternatives.supply<minsize] = 0\n",
      "                else: p[mask] = 0 # already chosen\n",
      "                #print \"Choosing from %d nonzero alts\" % np.count_nonzero(p)\n",
      "        \n",
      "                try: \n",
      "                  indexes = np.random.choice(len(alternatives.index),len(segment.index),replace=False,p=p/p.sum())\n",
      "                except:\n",
      "                  print \"WARNING: not enough options to fit agents, will result in unplaced agents\"\n",
      "                  return mask,new_homes\n",
      "                new_homes.ix[segment.index] = alternatives.index.values[indexes]\n",
      "            \n",
      "                if minsize is not None: alternatives[\"supply\"].ix[alternatives.index.values[indexes]] -= minsize\n",
      "                else: mask[indexes] = 1\n",
      "              \n",
      "                return mask,new_homes\n",
      "            if int(name) == 6:\n",
      "                mask,new_homes = choose(p,mask,alts6,segment,new_homes)\n",
      "            \n",
      "        build_cnts = new_homes.value_counts()  #num resunits place in each building\n",
      "        print \"Assigned %d agents to %d locations with %d unplaced\" % (new_homes.size,build_cnts.size,build_cnts.get(-1,0))\n",
      "        \n",
      "        table = nonres_units # need to go back to the whole dataset *****************\n",
      "        table[depvar].ix[new_homes.index] = new_homes.values.astype('int32')\n",
      "        dset.store_attr('nr'+output_varname,year,copy.deepcopy(table[depvar]))\n",
      "        new_nonres_construction_totals = table.groupby('building_id').size()*500\n",
      "        print 'Previous non-residential sqft total:'\n",
      "        print dset.buildings.non_residential_sqft.sum()\n",
      "        dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,new_nonres_construction_totals.index)] = dset.buildings.non_residential_sqft[np.in1d(dset.buildings.index,new_nonres_construction_totals.index)] + new_nonres_construction_totals\n",
      "        print 'Current non-residential sqft total:'\n",
      "        print dset.buildings.non_residential_sqft.sum()\n",
      "    \n",
      "    \n",
      "    #################     REPM\n",
      "        year = sim_year\n",
      "        buildings = dset.fetch('buildings')\n",
      "        output_csv, output_title, coeff_name, output_varname = [\"paris-coeff-hedonic.csv\",\"PARIS HEDONIC MODEL\",\"price_%s\",\"price\"]\n",
      "        ind_vars1 = ['in_paris_suburbs','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars2 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars3 = ['in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars4 = ['in_paris','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','percent_old','bati',\n",
      "                     'population_density','tco',]\n",
      "        ind_vars6 = ['in_paris','in_la_defense','in_new_town','in_paris_suburbs','csubway9','percent_low_income','cpraft90','cprbef15','bati',\n",
      "                     'employment_density','tax_on_professionals','tco',]\n",
      "        simrents = []\n",
      "        segments = buildings.groupby('building_type_id')\n",
      "        for name, segment in segments:\n",
      "            if name == 1:\n",
      "                indvars = ind_vars1\n",
      "            if name == 2:\n",
      "                indvars = ind_vars2\n",
      "            if name == 3:\n",
      "                indvars = ind_vars3\n",
      "            if name == 4:\n",
      "                indvars = ind_vars4\n",
      "            if name == 6:\n",
      "                indvars = ind_vars6\n",
      "            est_data = pd.DataFrame(index=segment.index)\n",
      "            for varname in indvars:\n",
      "                est_data[varname] = segment[varname]\n",
      "            est_data = est_data.fillna(0)\n",
      "            est_data = sm.add_constant(est_data,prepend=False)\n",
      "            tmp_outcsv, tmp_outtitle, tmp_coeffname = output_csv%name, output_title%name, coeff_name%name\n",
      "            print \"Generating rents on %d buildings\" % (est_data.shape[0])\n",
      "            vec = dset.load_coeff(tmp_coeffname)\n",
      "            vec = np.reshape(vec,(vec.size,1))\n",
      "            rents = est_data.dot(vec).astype('f4')\n",
      "            rents = rents.apply(np.exp)\n",
      "            simrents.append(rents[rents.columns[0]])\n",
      "            \n",
      "        simrents = pd.concat(simrents)\n",
      "        dset.buildings[output_varname] = simrents.reindex(dset.buildings.index)\n",
      "        dset.store_attr(output_varname,year,simrents)\n",
      "        \n",
      "    #######ANNUAL SUMMARY\n",
      "        b = dset.fetch('buildings')\n",
      "        e = dset.fetch('establishments')\n",
      "        hh = dset.fetch('households')\n",
      "        summary['employment'].append(e[e.building_id>0].employees.sum())\n",
      "        summary['households'].append(len(hh[hh.building_id>0].building_id))\n",
      "        summary['non_residential_sqft'].append(b.non_residential_sqft.sum())\n",
      "        summary['residential_units'].append(b.residential_units.sum())\n",
      "        summary['price'].append(b.price.mean())\n",
      "        \n",
      "        ##End-of-iteration calibration update\n",
      "        if sim_year == last_year:\n",
      "            print summary\n",
      "            hh['zone_id'] = b.zone_id[hh.building_id].values\n",
      "            e['zone_id'] = b.zone_id[e.building_id].values\n",
      "            z['total_households'] = hh.groupby('zone_id').building_id.count()\n",
      "            z['total_residential_units'] = b.groupby('zone_id').residential_units.sum()\n",
      "            z['total_nonresidential_sqft'] = b.groupby('zone_id').non_residential_sqft.sum()\n",
      "            z['total_employment'] = e.groupby('zone_id').employees.sum()\n",
      "            z['total_persons'] = hh.groupby('zone_id').persons.sum()\n",
      "            sim_pop = z.groupby('zgpgroup_id').total_persons.sum()\n",
      "            sim_emp = z.groupby('zgpgroup_id').total_employment.sum()\n",
      "            sim_hh = z.groupby('zgpgroup_id').total_households.sum()\n",
      "            sim_ru = z.groupby('zgpgroup_id').total_residential_units.sum()\n",
      "            sim_nr = z.groupby('zgpgroup_id').total_nonresidential_sqft.sum()\n",
      "            \n",
      "            emp_diff_zone = z.total_employment - base_emp_zone\n",
      "            pop_diff_zone = z.total_persons - base_pop_zone\n",
      "            zone_diffs = pd.DataFrame({'emp_diff':emp_diff_zone,'pop_diff':pop_diff_zone})\n",
      "            \n",
      "            pop_diff = sim_pop - base_pop\n",
      "            emp_diff = sim_emp - base_emp\n",
      "            hh_diff = sim_hh - base_hh\n",
      "            ru_diff = sim_ru - base_ru\n",
      "            nr_diff = sim_nr - base_nr\n",
      "            print 'Employment in 2035, by ZGPGroup'\n",
      "            print sim_emp\n",
      "            print 'Households in 2035, by ZGPGroup'\n",
      "            print sim_hh\n",
      "            print 'Population in 2035, by ZGPGroup'\n",
      "            print sim_pop\n",
      "            print 'Residential units in 2035, by ZGPGroup'\n",
      "            print sim_ru\n",
      "            print 'Non-residential sqft in 2035 by ZGPGroup'\n",
      "            print sim_nr\n",
      "            print 'Employment growth 1999-2035, by ZGPGroup'\n",
      "            print emp_diff\n",
      "            print 'Household growth 1999-2035, by ZGPGroup'\n",
      "            print hh_diff\n",
      "            print 'Population growth 1999-2035, by ZGPGroup'\n",
      "            print pop_diff\n",
      "            print 'Residential unit growth 1999-2035, by ZGPGroup'\n",
      "            print ru_diff\n",
      "            print 'Non-residential sqft growth 1999-2035 by ZGPGroup'\n",
      "            print nr_diff\n",
      "            \n",
      "            prop_growth_emp = emp_diff*1.0/emp_diff.sum()\n",
      "            prop_growth_hh = hh_diff*1.0/hh_diff.sum()\n",
      "            prop_growth_pop = pop_diff*1.0/pop_diff.sum()\n",
      "            prop_growth_ru = ru_diff*1.0/ru_diff.sum()\n",
      "            prop_growth_nr = nr_diff*1.0/nr_diff.sum()\n",
      "            perc_growth_hh = (hh_diff)*100.0/base_hh\n",
      "            perc_growth_pop = (pop_diff)*100.0/base_pop\n",
      "            perc_growth_emp = (emp_diff)*100.0/base_emp\n",
      "            perc_growth_ru = (ru_diff)*100.0/base_ru\n",
      "            perc_growth_nr = (nr_diff)*100.0/base_nr\n",
      "            print 'Proportion of employment growth captured by ZGPGroup'\n",
      "            print prop_growth_emp\n",
      "            print 'Proportion of household growth captured by ZGPGroup'\n",
      "            print prop_growth_hh\n",
      "            print 'Proportion of population growth captured by ZGPGroup'\n",
      "            print prop_growth_pop\n",
      "            print 'Proportion of residential unit growth captured by ZGPGroup'\n",
      "            print prop_growth_ru\n",
      "            print 'Proportion of non-residential sqft growth captured by ZGPGroup'\n",
      "            print prop_growth_nr\n",
      "            \n",
      "            print 'Percent employment growth, ZGPGroup'\n",
      "            print perc_growth_emp\n",
      "            print 'Perrcent household growth, ZGPGroup'\n",
      "            print perc_growth_hh\n",
      "            print 'Percent population growth, ZGPGroup'\n",
      "            print perc_growth_pop\n",
      "            print 'Percent residential unit growth, ZGPGroup'\n",
      "            print perc_growth_ru\n",
      "            print 'Percent non-residential sqft growth, ZGPGroup'\n",
      "            print perc_growth_nr\n",
      "            \n",
      "            population = pd.DataFrame({'simulated_amount':sim_pop,'difference':pop_diff,'proportion_captured':prop_growth_pop})\n",
      "            employment = pd.DataFrame({'simulated_amount':sim_emp,'difference':emp_diff,'proportion_captured':prop_growth_emp})\n",
      "            household = pd.DataFrame({'simulated_amount':sim_hh,'difference':hh_diff,'proportion_captured':prop_growth_hh})\n",
      "            residential_unit = pd.DataFrame({'simulated_amount':sim_ru,'difference':ru_diff,'proportion_captured':prop_growth_ru})\n",
      "            nonres_sqft = pd.DataFrame({'simulated_amount':sim_nr,'difference':nr_diff,'proportion_captured':prop_growth_nr})\n",
      "            \n",
      "            population.to_csv(output_dir + '\\\\' + scenario+ title + '_population.csv')\n",
      "            employment.to_csv(output_dir + '\\\\' + scenario+ title + '_employment.csv')\n",
      "            household.to_csv(output_dir + '\\\\' + scenario+ title + '_households.csv')\n",
      "            residential_unit.to_csv(output_dir + '\\\\' + scenario+ title + '_residential_units.csv')\n",
      "            nonres_sqft.to_csv(output_dir + '\\\\' + scenario+ title + '_nonresidential_sqft.csv')\n",
      "            \n",
      "            zone_diffs.to_csv(output_dir + '\\\\' + scenario + title + '_zone_diffs.csv')\n",
      "            \n",
      "            estabs_base = dset.store.establishments\n",
      "            b = dset.fetch('buildings')\n",
      "            estabs_base['dept_id'] = b.dept_id[estabs_base.building_id].values\n",
      "            estabs_base_by_dept = estabs_base.groupby('dept_id').employees.sum()\n",
      "            estabs_sim = dset.fetch('establishments')\n",
      "            estabs_sim['dept_id'] = b.dept_id[estabs_sim.building_id].values\n",
      "            estabs_sim_by_dept = estabs_sim.groupby('dept_id').employees.sum()\n",
      "            print 'Dept Growth Rate, Employment'\n",
      "            print (estabs_sim_by_dept - estabs_base_by_dept)*1.0/estabs_base_by_dept \n",
      "            \n",
      "            hh_base = dset.store.households\n",
      "            b = dset.fetch('buildings')\n",
      "            hh_base['dept_id'] = b.dept_id[hh_base.building_id].values\n",
      "            hh_base_by_dept = hh_base.groupby('dept_id').building_id.count()\n",
      "            hh_sim = dset.fetch('households')\n",
      "            hh_sim['dept_id'] = b.dept_id[hh_sim.building_id].values\n",
      "            hh_sim_by_dept = hh_sim.groupby('dept_id').building_id.count()\n",
      "            print 'Dept Growth Rate, Households'\n",
      "            print (hh_sim_by_dept - hh_base_by_dept)*1.0/hh_base_by_dept\n",
      "            \n",
      "            z['resunits_base'] = dset.store.buildings.groupby('zone_id').residential_units.sum()\n",
      "            resunits_base_by_dept = z.groupby('dept_id').resunits_base.sum()\n",
      "            b = dset.fetch('buildings')\n",
      "            resunits_sim_by_dept = b.groupby('dept_id').residential_units.sum()\n",
      "            print 'Dept Growth Rate, Residential Units'\n",
      "            print (resunits_sim_by_dept - resunits_base_by_dept)*1.0/resunits_base_by_dept\n",
      "        \n",
      "            z['nonres_sqft_base'] = dset.store.buildings.groupby('zone_id').non_residential_sqft.sum()\n",
      "            nonres_sqft_base_by_dept = z.groupby('dept_id').nonres_sqft_base.sum()\n",
      "            b = dset.fetch('buildings')\n",
      "            nonres_sqft_sim_by_dept = b.groupby('dept_id').non_residential_sqft.sum()\n",
      "            print 'Dept Growth Rate, Non-residential sqft'\n",
      "            print (nonres_sqft_sim_by_dept - nonres_sqft_base_by_dept)*1.0/nonres_sqft_base_by_dept\n",
      "            \n",
      "            sim_store_path = os.path.join(output_dir,'sim_store.h5')\n",
      "            sim_store = pd.HDFStore(sim_store_path)\n",
      "            sim_store[scenario+ title + '_households'] = hh\n",
      "            sim_store[scenario+ title + '_establishments'] = e\n",
      "            sim_store[scenario+ title + '_buildings'] = b\n",
      "            sim_store.close()\n",
      "            \n",
      "    elapsed = time.time() - seconds_start\n",
      "    print \"TOTAL elapsed time: \" + str(elapsed) + \" seconds.\"\n",
      "    \n",
      "print 'Done running all three scenarios.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "cannot create BlockManager._ref_locs because block [FloatBlock: [zone_id_x, building_sqft_per_job, non_residential_units, base_year_jobs, all_units, residential_units_zone_x, non_residential_sqft_zone_x, residential_units_zone_y, non_residential_sqft_zone_y], 9 x 881750, dtype float64] with duplicate items [Index([u'building_type_id', u'improvement_value', u'land_area', u'non_residential_sqft', u'parcel_id', u'residential_units', u'sqft_per_unit', u'stories', u'tax_exempt', u'year_built', u'bldg_sq_ft', u'unit_price_non_residential', u'unit_price_residential', u'zone_id_x', u'building_sqft_per_job', u'non_residential_units', u'base_year_jobs', u'all_units', u'btype', u'county_id_x', u'parcel_sqft_x', u'land_value_x', u'zone_id_y', u'city_id_x', u'gen_lu_type_id_x', u'lu_type_id_x', u'tax_exempt_flag_x', u'school_district_x', u'zoning_id_x', u'dist_bus_x', u'dist_rail_x', u'in_ugb_x', u'in_uga_x', u'env_constr_park_x', u'env_constr_lake_x', u'env_constr_floodplain_x', u'env_constr_river_x', u'env_constr_landslide_x', u'far_id_x', u'prop_constrained_x', u'in_denver_x', u'external_zone_id_x', u'area_x', u'acreage_x', u'modelarea_x', u'area_type_x', u'zonecentroid_x_x', u'zonecentroid_y_x', u'county_x', u'numtransstops_x', u'averagedailyparkingcost_x', u'intrdenshhbuffer_x', u'intrdensempbuffer_x', u'private_pk8enrollment_x', u'public_pk8enrollment_x', u'total_pk8enrollment_x', u'private_912enrollment_x', u'public_912enrollment_x', u'total_912enrollment_x', u'universityenrollment_x', u'schooldistrictzone_x', u'schooldistrictname_x', u'newdistrictname_x', u'newdistrictid_x', u'totalzonalenrollment_x', u'escort_agglogsum_x', u'persbus_agglogsum_x', u'shop_agglogsum_x', u'meal_agglogsum_x', u'socrec_agglogsum_x', u'workbasedsubtour_agglogsum_x', u'allpurpose_agglosum_x', u'school_district_id_x', u'residential_units_zone_x', u'non_residential_sqft_zone_x', u'zone_id_x', u'county_id_y', u'parcel_sqft_y', u'land_value_y', u'zone_id_y', u'city_id_y', u'gen_lu_type_id_y', u'lu_type_id_y', u'tax_exempt_flag_y', u'school_district_y', u'zoning_id_y', u'dist_bus_y', u'dist_rail_y', u'in_ugb_y', u'in_uga_y', u'env_constr_park_y', u'env_constr_lake_y', u'env_constr_floodplain_y', u'env_constr_river_y', u'env_constr_landslide_y', u'far_id_y', u'prop_constrained_y', u'in_denver_y', u'external_zone_id_y', u'area_y', u'acreage_y', u'modelarea_y', u'area_type_y', u'zonecentroid_x_y', u'zonecentroid_y_y', u'county_y', u'numtransstops_y', u'averagedailyparkingcost_y', u'intrdenshhbuffer_y', u'intrdensempbuffer_y', u'private_pk8enrollment_y', u'public_pk8enrollment_y', u'total_pk8enrollment_y', u'private_912enrollment_y', u'public_912enrollment_y', u'total_912enrollment_y', u'universityenrollment_y', u'schooldistrictzone_y', u'schooldistrictname_y', u'newdistrictname_y', u'newdistrictid_y', u'totalzonalenrollment_y', u'escort_agglogsum_y', u'persbus_agglogsum_y', u'shop_agglogsum_y', u'meal_agglogsum_y', u'socrec_agglogsum_y', u'workbasedsubtour_agglogsum_y', u'allpurpose_agglosum_y', u'school_district_id_y', u'residential_units_zone_y', u'non_residential_sqft_zone_y'], dtype=object)] does not have _ref_locs set",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-79b04c67a2a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mpz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zone_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#merge buildings with parcels/zones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mdset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'buildings'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'parcel_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m#Record base values for temporal comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                          copy=copy)\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m                                       copy=self.copy)\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mresult_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[0mresult_blocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_blk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_merged_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_merge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;31m# we have a duplicate items index, setup the block maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_ref_locs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_refs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_set_ref_locs\u001b[1;34m(self, labels, do_refs)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                         raise AssertionError(\"cannot create BlockManager._ref_locs because \"\n\u001b[0;32m   1116\u001b[0m                                              \u001b[1;34m\"block [%s] with duplicate items [%s] \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m                                              \"does not have _ref_locs set\" % (block,labels))\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m                     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_create_block_in_items_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAssertionError\u001b[0m: cannot create BlockManager._ref_locs because block [FloatBlock: [zone_id_x, building_sqft_per_job, non_residential_units, base_year_jobs, all_units, residential_units_zone_x, non_residential_sqft_zone_x, residential_units_zone_y, non_residential_sqft_zone_y], 9 x 881750, dtype float64] with duplicate items [Index([u'building_type_id', u'improvement_value', u'land_area', u'non_residential_sqft', u'parcel_id', u'residential_units', u'sqft_per_unit', u'stories', u'tax_exempt', u'year_built', u'bldg_sq_ft', u'unit_price_non_residential', u'unit_price_residential', u'zone_id_x', u'building_sqft_per_job', u'non_residential_units', u'base_year_jobs', u'all_units', u'btype', u'county_id_x', u'parcel_sqft_x', u'land_value_x', u'zone_id_y', u'city_id_x', u'gen_lu_type_id_x', u'lu_type_id_x', u'tax_exempt_flag_x', u'school_district_x', u'zoning_id_x', u'dist_bus_x', u'dist_rail_x', u'in_ugb_x', u'in_uga_x', u'env_constr_park_x', u'env_constr_lake_x', u'env_constr_floodplain_x', u'env_constr_river_x', u'env_constr_landslide_x', u'far_id_x', u'prop_constrained_x', u'in_denver_x', u'external_zone_id_x', u'area_x', u'acreage_x', u'modelarea_x', u'area_type_x', u'zonecentroid_x_x', u'zonecentroid_y_x', u'county_x', u'numtransstops_x', u'averagedailyparkingcost_x', u'intrdenshhbuffer_x', u'intrdensempbuffer_x', u'private_pk8enrollment_x', u'public_pk8enrollment_x', u'total_pk8enrollment_x', u'private_912enrollment_x', u'public_912enrollment_x', u'total_912enrollment_x', u'universityenrollment_x', u'schooldistrictzone_x', u'schooldistrictname_x', u'newdistrictname_x', u'newdistrictid_x', u'totalzonalenrollment_x', u'escort_agglogsum_x', u'persbus_agglogsum_x', u'shop_agglogsum_x', u'meal_agglogsum_x', u'socrec_agglogsum_x', u'workbasedsubtour_agglogsum_x', u'allpurpose_agglosum_x', u'school_district_id_x', u'residential_units_zone_x', u'non_residential_sqft_zone_x', u'zone_id_x', u'county_id_y', u'parcel_sqft_y', u'land_value_y', u'zone_id_y', u'city_id_y', u'gen_lu_type_id_y', u'lu_type_id_y', u'tax_exempt_flag_y', u'school_district_y', u'zoning_id_y', u'dist_bus_y', u'dist_rail_y', u'in_ugb_y', u'in_uga_y', u'env_constr_park_y', u'env_constr_lake_y', u'env_constr_floodplain_y', u'env_constr_river_y', u'env_constr_landslide_y', u'far_id_y', u'prop_constrained_y', u'in_denver_y', u'external_zone_id_y', u'area_y', u'acreage_y', u'modelarea_y', u'area_type_y', u'zonecentroid_x_y', u'zonecentroid_y_y', u'county_y', u'numtransstops_y', u'averagedailyparkingcost_y', u'intrdenshhbuffer_y', u'intrdensempbuffer_y', u'private_pk8enrollment_y', u'public_pk8enrollment_y', u'total_pk8enrollment_y', u'private_912enrollment_y', u'public_912enrollment_y', u'total_912enrollment_y', u'universityenrollment_y', u'schooldistrictzone_y', u'schooldistrictname_y', u'newdistrictname_y', u'newdistrictid_y', u'totalzonalenrollment_y', u'escort_agglogsum_y', u'persbus_agglogsum_y', u'shop_agglogsum_y', u'meal_agglogsum_y', u'socrec_agglogsum_y', u'workbasedsubtour_agglogsum_y', u'allpurpose_agglosum_y', u'school_district_id_y', u'residential_units_zone_y', u'non_residential_sqft_zone_y'], dtype=object)] does not have _ref_locs set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running scenario: baseline\n",
        "1389808258.24\n",
        "Simulating year 2010\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}